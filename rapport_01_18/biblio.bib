
@article{choset_topological_2001,
 title = {Topological simultaneous localization and mapping ({SLAM}): toward exact localization without explicit localization},
 volume = {17},
 issn = {1042296X},
 url = {http://ieeexplore.ieee.org/document/928558/},
 doi = {10.1109/70.928558},
 shorttitle = {Topological simultaneous localization and mapping ({SLAM})},
 pages = {125--137},
 number = {2},
 journaltitle = {{IEEE} Transactions on Robotics and Automation},
 author = {Choset, H. and Nagatani, K.},
 urldate = {2017-02-13},
 date = {2001-04}
}

@article{ollero_multiple_2005,
 title = {Multiple eyes in the skies: architecture and perception issues in the {COMETS} unmanned air vehicles project},
 volume = {12},
 issn = {1070-9932},
 doi = {10.1109/MRA.2005.1458323},
 shorttitle = {Multiple eyes in the skies},
 abstract = {This paper describes the {COMETS} (Real-Time Coordination and Control of Multiple Heterogeneous Unmanned Aerial Vehicles) Project, which is aimed at designing and implementing a system for cooperative activities using heterogeneous {UAVs}. Heterogeneity is considered both in terms of aerial vehicles and onboard processing capabilities ranging from fully autonomous systems to conventional remotely piloted vehicles. {COMETS} also involves cooperative environmental perception including fire detection and monitoring as well as terrain mapping.},
 pages = {46--57},
 number = {2},
 journaltitle = {{IEEE} Robotics Automation Magazine},
 author = {Ollero, A. and Lacroix, S. and Merino, L. and Gancet, J. and Wiklund, J. and Remuss, V. and Perez, I. V. and Gutierrez, L. G. and Viegas, D. X. and Benitez, M. A. G. and Mallet, A. and Alami, R. and Chatila, R. and Hommel, G. and Lechuga, F. J. C. and Arrue, B. C. and Ferruz, J. and Dios, J. R. Martinez-De and Caballero, F.},
 date = {2005-06},
 keywords = {{COMETS} unmanned air vehicles project, Eyes, Fires, Land vehicles, Monitoring, Remotely operated vehicles, Research and development, Robotics and automation, Sensor arrays, Unmanned aerial vehicles, aerospace robotics, autonomous vehicle, conventional remotely piloted vehicles, distributed aerial robotics, fully autonomous systems, helicopters, mobile robots, onboard processing capabilities, teleoperated vehicle, telerobotics},
 file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/PGVUTN6R/1458323.html:text/html;IEEE Xplore Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/CJB7BMTV/Ollero et al. - 2005 - Multiple eyes in the skies architecture and perce.pdf:application/pdf}
}

@article{lu_globally_1997,
 title = {Globally consistent range scan alignment for environment mapping},
 volume = {4},
 url = {http://link.springer.com/article/10.1023/A:1008854305733},
 pages = {333--349},
 number = {4},
 journaltitle = {Autonomous robots},
 author = {Lu, Feng and Milios, Evangelos},
 urldate = {2017-05-10},
 date = {1997},
 file = {Globally Consistent Range Scan Alignment for Environment Mapping - art%3A10.1023%2FA%3A1008854305733.pdf:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/NI827UMM/art%3A10.1023%2FA%3A1008854305733.pdf:application/pdf}
 }

 @inproceedings{hong_vicp:_2010,
  title = {{VICP}: Velocity updating iterative closest point algorithm},
  doi = {10.1109/ROBOT.2010.5509312},
  shorttitle = {{VICP}},
  abstract = {We propose a novel method to enhance a family of {ICP}(iterative closest point) algorithms by updating velocity. Even though {ICP} algorithms play a dominant role in a model based tracking, it is difficult to avoid an accumulated tracking error during a continuous motion. It is because that typical {ICP} algorithms assumes that each of the point in one scan are measured simultaneously while most of the available rangefinders measure each point sequentially. Hence conventional {ICP} algorithms are prone to be erroneous under a fast motion and an accumulated error during the motion cannot be ignored in many cases. In our approach, we estimate a velocity of a rangefinder numerically over {ICP} iterations. As a result, distortion of a scan due to the motion can be compensated using estimated velocity. In addition, outliers are effectively rejected during the iteration of velocity update, which means that more accurate and robust motion is trackable. Also we verify a performance and an accuracy of our method by demonstrating simulation and real-world experiment results.},
  eventtitle = {2010 {IEEE} International Conference on Robotics and Automation},
  pages = {1893--1898},
  booktitle = {2010 {IEEE} International Conference on Robotics and Automation},
  author = {Hong, S. and Ko, H. and Kim, J.},
  date = {2010-05},
  keywords = {Distortion measurement, {ICP} iterations, Iterative algorithms, Iterative closest point algorithm, Laser noise, Robot kinematics, Robot sensing systems, Robotics and automation, {USA} Councils, {VICP}, iterative methods, mobile robots, model based tracking, motion compensation, tracking, velocity updating iterative closest point algorithm},
  file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/7USHQ2K3/5509312.html:text/html;IEEE Xplore Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/I7V5SNJI/Hong et al. - 2010 - VICP Velocity updating iterative closest point al.pdf:application/pdf}
 }

 @thesis{fenwick_collaborative_2001,
  title = {Collaborative concurrent mapping and localization},
  url = {https://pdfs.semanticscholar.org/0c95/173efb7058f53a7e49e9566a9de4a1e1f7c1.pdf},
  institution = {Massachusetts Institute of Technology},
  type = {phdthesis},
  author = {Fenwick, John William},
  urldate = {2017-04-07},
  date = {2001},
  file = {173efb7058f53a7e49e9566a9de4a1e1f7c1.pdf:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/T4I53UK8/173efb7058f53a7e49e9566a9de4a1e1f7c1.pdf:application/pdf}
 }

 @article{bajcsy_active_1992,
  title = {Active and exploratory perception},
  volume = {56},
  url = {http://www.sciencedirect.com/science/article/pii/104996609290083F},
  pages = {31--40},
  number = {1},
  journaltitle = {{CVGIP}: Image Understanding},
  author = {Bajcsy, Ruzena and Campos, Mario},
  urldate = {2017-04-24},
  date = {1992},
  file = {PII\: 1049-9660(92)90083-F - 1-s2.0-104996609290083F-main.pdf:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/KQA62TRH/1-s2.0-104996609290083F-main.pdf:application/pdf}
 }

 @article{scherer_river_2012,
  title = {River mapping from a flying robot: state estimation, river detection, and obstacle mapping},
  volume = {33},
  issn = {0929-5593, 1573-7527},
  url = {http://link.springer.com/10.1007/s10514-012-9293-0},
  doi = {10.1007/s10514-012-9293-0},
  shorttitle = {River mapping from a flying robot},
  pages = {189--214},
  number = {1},
  journaltitle = {Autonomous Robots},
  author = {Scherer, Sebastian and Rehder, Joern and Achar, Supreeth and Cover, Hugh and Chambers, Andrew and Nuske, Stephen and Singh, Sanjiv},
  urldate = {2017-05-15},
  date = {2012-08},
  langid = {english},
  file = {art%3A10.1007%2Fs10514-012-9293-0.pdf:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/NQKTUXTF/art%3A10.1007%2Fs10514-012-9293-0.pdf:application/pdf}
  }

  @article{howard_experiments_2006,
   title = {Experiments with a Large Heterogeneous Mobile Robot Team: Exploration, Mapping, Deployment and Detection},
   volume = {25},
   issn = {0278-3649, 1741-3176},
   url = {http://journals.sagepub.com/doi/10.1177/0278364906065378},
   doi = {10.1177/0278364906065378},
   shorttitle = {Experiments with a Large Heterogeneous Mobile Robot Team},
   pages = {431--447},
   number = {5},
   journaltitle = {The International Journal of Robotics Research},
   author = {Howard, Andrew and Parker, Lynne E. and Sukhatme, Gaurav S.},
   urldate = {2017-04-24},
   date = {2006-05},
   langid = {english},
   file = {0278364906065378:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/CM8I7Z3B/0278364906065378.pdf:application/pdf}
  }

  @inproceedings{engel_large-scale_2015,
   title = {Large-scale direct {SLAM} with stereo cameras},
   url = {http://ieeexplore.ieee.org/abstract/document/7353631/},
   pages = {1935--1942},
   booktitle = {Intelligent Robots and Systems ({IROS}), 2015 {IEEE}/{RSJ} International Conference on},
   publisher = {{IEEE}},
   author = {Engel, Jakob and Stückler, Jörg and Cremers, Daniel},
   urldate = {2017-05-02},
   date = {2015},
   file = {engel2015_stereo_lsdslam.pdf:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/W4SC9XNR/engel2015_stereo_lsdslam.pdf:application/pdf}
  }

  @article{li_navigation_2005,
   title = {Navigation protocols in sensor networks},
   volume = {1},
   url = {http://dl.acm.org/citation.cfm?id=1077393},
   pages = {3--35},
   number = {1},
   journaltitle = {{ACM} Transactions on Sensor Networks ({TOSN})},
   author = {Li, Qun and Rus, Daniela},
   urldate = {2017-04-24},
   date = {2005},
   file = {ACMJ063-01.tex - p3-li.pdf:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/F543TV9G/p3-li.pdf:application/pdf}
  }

  @article{davison_monoslam:_2007,
   title = {{MonoSLAM}: Real-Time Single Camera {SLAM}},
   volume = {29},
   issn = {0162-8828},
   doi = {10.1109/TPAMI.2007.1049},
   shorttitle = {{MonoSLAM}},
   abstract = {We present a real-time algorithm which can recover the 3D trajectory of a monocular camera, moving rapidly through a previously unknown scene. Our system, which we dub {MonoSLAM}, is the first successful application of the {SLAM} methodology from mobile robotics to the "pure vision" domain of a single uncontrolled camera, achieving real time but drift-free performance inaccessible to structure from motion approaches. The core of the approach is the online creation of a sparse but persistent map of natural landmarks within a probabilistic framework. Our key novel contributions include an active approach to mapping and measurement, the use of a general motion model for smooth camera movement, and solutions for monocular feature initialization and feature orientation estimation. Together, these add up to an extremely efficient and robust algorithm which runs at 30 Hz with standard {PC} and camera hardware. This work extends the range of robotic systems in which {SLAM} can be usefully applied, but also opens up new areas. We present applications of {MonoSLAM} to real-time 3D localization and mapping for a high-performance full-size humanoid robot and live augmented reality with a hand-held camera},
   pages = {1052--1067},
   number = {6},
   journaltitle = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
   author = {Davison, A. J. and Reid, I. D. and Molton, N. D. and Stasse, O.},
   date = {2007-06},
   keywords = {3D trajectory, 3D/stereo scene analysis, Algorithms, Artificial Intelligence, Autonomous vehicles, Computer Systems, Hardware, Image Enhancement, Image Interpretation, Computer-Assisted, Imaging, Three-Dimensional, Information Storage and Retrieval, Layout, {MonoSLAM}, Motion estimation, Motion measurement, Numerical Analysis, Computer-Assisted, Pattern Recognition, Automated, Photogrammetry, Real time systems, Robot vision systems, Robustness, {SLAM} (robots), Signal Processing, Computer-Assisted, Video Recording, cameras, feature extraction, feature orientation estimation, humanoid robot, humanoid robots, image sensors, mobile robots, monocular camera, real-time single camera {SLAM}, simultaneous localization and mapping, tracking.},
   file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/WRXDNRK5/4160954.html:text/html;IEEE Xplore Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/CBDQ5P9G/Davison et al. - 2007 - MonoSLAM Real-Time Single Camera SLAM.pdf:application/pdf}
  }

  @article{jung_development_2015,
   title = {Development of Kinematic 3D Laser Scanning System for Indoor Mapping and As-Built {BIM} Using Constrained {SLAM}},
   volume = {15},
   issn = {1424-8220},
   url = {http://www.mdpi.com/1424-8220/15/10/26430/},
   doi = {10.3390/s151026430},
   pages = {26430--26456},
   number = {10},
   journaltitle = {Sensors},
   author = {Jung, Jaehoon and Yoon, Sanghyun and Ju, Sungha and Heo, Joon},
   urldate = {2017-05-03},
   date = {2015-10-16},
   langid = {english},
   file = {sensors-15-26430.pdf:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/KWTB3WAI/sensors-15-26430.pdf:application/pdf}
  }

  @article{beard_coordination_2001,
   title = {A coordination architecture for spacecraft formation control},
   volume = {9},
   issn = {1063-6536},
   doi = {10.1109/87.960341},
   abstract = {This paper addresses the problem of coordinating multiple spacecraft to fly in tightly controlled formations. The main contribution of the paper is to introduce a coordination architecture that subsumes leader-following, behavioral, and virtual-structure approaches to the multiagent coordination problem. The architecture is illustrated through a detailed application of the ideas to the problem of synthesizing a multiple spacecraft interferometer in deep space},
   pages = {777--790},
   number = {6},
   journaltitle = {{IEEE} Transactions on Control Systems Technology},
   author = {Beard, R. W. and Lawton, J. and Hadaegh, F. Y.},
   date = {2001-11},
   keywords = {Instruments, Laboratories, Military aircraft, Orbital robotics, Propulsion, Robot kinematics, Space technology, Topology, aerospace control, coordinated control, deep space, formation flying, interferometers, leader-following, mobile robots, multiagent coordination, multiple spacecraft coordination, multiple spacecraft interferometer, space vehicles, spacecraft formation control},
   file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/VIAWR4D5/960341.html:text/html;IEEE Xplore Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/VMBU5KC8/Beard et al. - 2001 - A coordination architecture for spacecraft formati.pdf:application/pdf}
  }

  @inproceedings{lategahn_visual_2011,
   title = {Visual {SLAM} for autonomous ground vehicles},
   doi = {10.1109/ICRA.2011.5979711},
   abstract = {Simultaneous Localization and Mapping ({SLAM}) and Visual {SLAM} (V-{SLAM}) in particular have been an active area of research lately. In V-{SLAM} the main focus is most often laid on the localization part of the problem allowing for a drift free motion estimate. To this end, a sparse set of landmarks is tracked and their position is estimated. However, this set of landmarks (rendering the map) is often too sparse for tasks in autonomous driving such as navigation, path planning, obstacle avoidance etc. Some methods keep the raw measurements for past robot poses to address the sparsity problem often resulting in a pose only {SLAM} akin to laser scanner {SLAM}. For the stereo case, this is however impractical due to the high noise of stereo reconstructed point clouds. In this paper we propose a dense stereo V-{SLAM} algorithm that estimates a dense 3D map representation which is more accurate than raw stereo measurements. Thereto, we run a sparse V {SLAM} system, take the resulting pose estimates to compute a locally dense representation from dense stereo correspondences. This dense representation is expressed in local coordinate systems which are tracked as part of the {SLAM} estimate. This allows the dense part to be continuously updated. Our system is driven by visual odometry priors to achieve high robustness when tracking landmarks. Moreover, the sparse part of the {SLAM} system uses recently published sub mapping techniques to achieve constant runtime complexity most of the time. The improved accuracy over raw stereo measurements is shown in a Monte Carlo simulation. Finally, we demonstrate the feasibility of our method by presenting outdoor experiments of a car like robot.},
   eventtitle = {2011 {IEEE} International Conference on Robotics and Automation},
   pages = {1732--1737},
   booktitle = {2011 {IEEE} International Conference on Robotics and Automation},
   author = {Lategahn, H. and Geiger, A. and Kitt, B.},
   date = {2011-05},
   keywords = {Accuracy, Kalman filters, Monte Carlo methods, Monte Carlo simulation, Motion estimation, Navigation, {SLAM} (robots), Visualization, autonomous driving, autonomous ground vehicles, cameras, car like robot, collision avoidance, dense 3D map representation, drift free motion estimate, image reconstruction, image representation, landmark tracking, local coordinate system, mobile robots, object tracking, obstacle avoidance, path planning, pose estimate, pose estimation, position estimation, road vehicles, robot pose, robot vision, runtime complexity, simultaneous localization and mapping, sparsity problem, stereo image processing, stereo reconstructed point clouds, submapping technique, visual {SLAM}, visual odometry},
   file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/NCQK3U45/5979711.html:text/html;IEEE Xplore Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/94RCQMX3/Lategahn et al. - 2011 - Visual SLAM for autonomous ground vehicles.pdf:application/pdf}
  }

  @inproceedings{sun_programming_2016,
   title = {Programming human-like point-to-point approaching movement by demonstrations with Large-Scale Direct Monocular {SLAM}},
   doi = {10.1109/ROBIO.2016.7866539},
   abstract = {With the development of robotic technologies over last decades, the robotic mapping or the simultaneous localization and mapping ({SLAM}) has got matured correspondingly. The Large-Scale Direct Monocular {SLAM} ({LSD}-{SLAM}) is among the most promising methods in {SLAM}, which not only locally tracks the motion of the camera, but allows to build consistent and large-scale maps of the environment. In this paper, {LSD}-{SLAM} is implemented to model the surrounding environment of a three degrees-of-freedom robot manipulator. All the objects in the robot workspace have been recognized and located. And the robot will take the extracted information as visual input to perform a point-to-point approaching task A novel motion planning technique, programming by demonstrations ({PbD}), is used to transfer human approaching skills to the robot. Gaussian Mixture Models ({GMM}) and Gaussian Mixture Regression ({GMR}) are used to encode human demonstrations with a first-order differential dynamical systems model. Experimental results have verified the effectiveness of the proposed methods.},
   eventtitle = {2016 {IEEE} International Conference on Robotics and Biomimetics ({ROBIO})},
   pages = {1498--1503},
   booktitle = {2016 {IEEE} International Conference on Robotics and Biomimetics ({ROBIO})},
   author = {Sun, P. and Chen, J. and Lau, H. Y. K.},
   date = {2016-12},
   keywords = {Filtering, Gaussian mixture model, Gaussian mixture regression, Gaussian processes, {LSD}-{SLAM}, Modeling, Robot kinematics, {SLAM} (robots), Three-dimensional displays, cameras, degrees-of-freedom robot manipulator, human-like point-to-point approaching movement, large-scale direct monocular {SLAM}, manipulators, mixture models, motion planning technique, path planning, point-to-point approaching task, programming by demonstrations, regression analysis, robotic mapping, simultaneous localization and mapping},
   file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/Z79BMD3Q/7866539.html:text/html;IEEE Xplore Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/VAKBM6RS/Sun et al. - 2016 - Programming human-like point-to-point approaching .pdf:application/pdf}
  }

  @article{mur-artal_orb-slam:_2015,
   title = {{ORB}-{SLAM}: A Versatile and Accurate Monocular {SLAM} System},
   volume = {31},
   issn = {1552-3098},
   doi = {10.1109/TRO.2015.2463671},
   shorttitle = {{ORB}-{SLAM}},
   abstract = {This paper presents {ORB}-{SLAM}, a feature-based monocular simultaneous localization and mapping ({SLAM}) system that operates in real time, in small and large indoor and outdoor environments. The system is robust to severe motion clutter, allows wide baseline loop closing and relocalization, and includes full automatic initialization. Building on excellent algorithms of recent years, we designed from scratch a novel system that uses the same features for all {SLAM} tasks: tracking, mapping, relocalization, and loop closing. A survival of the fittest strategy that selects the points and keyframes of the reconstruction leads to excellent robustness and generates a compact and trackable map that only grows if the scene content changes, allowing lifelong operation. We present an exhaustive evaluation in 27 sequences from the most popular datasets. {ORB}-{SLAM} achieves unprecedented performance with respect to other state-of-the-art monocular {SLAM} approaches. For the benefit of the community, we make the source code public.},
   pages = {1147--1163},
   number = {5},
   journaltitle = {{IEEE} Transactions on Robotics},
   author = {Mur-Artal, R. and Montiel, J. M. M. and Tardós, J. D.},
   date = {2015-10},
   keywords = {Computational modeling, Lifelong mapping, {ORB}-{SLAM} system, Optimization, Real-time systems, {SLAM} (robots), Visualization, cameras, feature extraction, feature-based monocular simultaneous localization and mapping system, localization, monocular vision, recognition, simultaneous localization and mapping, simultaneous localization and mapping ({SLAM}), survival of the fittest strategy},
   file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/XQ4M8VWX/7219438.html:text/html;IEEE Xplore Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/U6FIW95A/Mur-Artal et al. - 2015 - ORB-SLAM A Versatile and Accurate Monocular SLAM .pdf:application/pdf}
  }

  @article{civera_inverse_2008,
   title = {Inverse Depth Parametrization for Monocular {SLAM}},
   volume = {24},
   issn = {1552-3098},
   doi = {10.1109/TRO.2008.2003276},
   abstract = {We present a new parametrization for point features within monocular simultaneous localization and mapping ({SLAM}) that permits efficient and accurate representation of uncertainty during undelayed initialization and beyond, all within the standard extended Kalman filter ({EKF}). The key concept is direct parametrization of the inverse depth of features relative to the camera locations from which they were first viewed, which produces measurement equations with a high degree of linearity. Importantly, our parametrization can cope with features over a huge range of depths, even those that are so far from the camera that they present little parallax during motion—maintaining sufficient representative uncertainty that these points retain the opportunity to "come in” smoothly from infinity if the camera makes larger movements. Feature initialization is undelayed in the sense that even distant features are immediately used to improve camera motion estimates, acting initially as bearing references but not permanently labeled as such. The inverse depth parametrization remains well behaved for features at all stages of {SLAM} processing, but has the drawback in computational terms that each point is represented by a 6-D state vector as opposed to the standard three of a Euclidean {XYZ} representation. We show that once the depth estimate of a feature is sufficiently accurate, its representation can safely be converted to the Euclidean {XYZ} form, and propose a linearity index that allows automatic detection and conversion to maintain maximum efficiency—only low parallax features need be maintained in inverse depth form for long periods. We present a real-time implementation at 30 Hz, where the parametrization is validated in a fully automatic 3-D {SLAM} system featuring a handheld single camera with no additional sensing. Experiments show robust operation in challenging indoor and outdoor environments with a very large ranges of scene depth, varied motion, and als- - o real time 360deg loop closing.},
   pages = {932--945},
   number = {5},
   journaltitle = {{IEEE} Transactions on Robotics},
   author = {Civera, J. and Davison, A. J. and Montiel, J. M. M.},
   date = {2008-10},
   keywords = {Extended Kalman filter, Kalman filters, Monocular simultaneous localization and mapping ({SLAM}), Motion estimation, {SLAM} (robots), camera motion estimates, feature initialization, image sensors, inverse depth parametrization, monocular {SLAM}, monocular simultaneous localization and mapping, nonlinear filters, real-time vision},
   file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/EFZQQJ6V/4637878.html:text/html;IEEE Xplore Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/E3PE536N/Civera et al. - 2008 - Inverse Depth Parametrization for Monocular SLAM.pdf:application/pdf}
  }

  @inproceedings{zhang_visual-lidar_2015,
   title = {Visual-lidar odometry and mapping: low-drift, robust, and fast},
   doi = {10.1109/ICRA.2015.7139486},
   shorttitle = {Visual-lidar odometry and mapping},
   abstract = {Here, we present a general framework for combining visual odometry and lidar odometry in a fundamental and first principle method. The method shows improvements in performance over the state of the art, particularly in robustness to aggressive motion and temporary lack of visual features. The proposed on-line method starts with visual odometry to estimate the ego-motion and to register point clouds from a scanning lidar at a high frequency but low fidelity. Then, scan matching based lidar odometry refines the motion estimation and point cloud registration simultaneously.We show results with datasets collected in our own experiments as well as using the {KITTI} odometry benchmark. Our proposed method is ranked \#1 on the benchmark in terms of average translation and rotation errors, with a 0.75\% of relative position drift. In addition to comparison of the motion estimation accuracy, we evaluate robustness of the method when the sensor suite moves at a high speed and is subject to significant ambient lighting changes.},
   eventtitle = {2015 {IEEE} International Conference on Robotics and Automation ({ICRA})},
   pages = {2174--2181},
   booktitle = {2015 {IEEE} International Conference on Robotics and Automation ({ICRA})},
   author = {Zhang, J. and Singh, S.},
   date = {2015-05},
   keywords = {Distortion, {KITTI} odometry benchmark, Laser radar, Motion estimation, Three-dimensional displays, Visualization, aggressive motion, ambient lighting changes, cameras, distance measurement, ego-motion estimation, feature extraction, first principle method, image matching, image registration, optical radar, point cloud registration, scan matching based lidar odometry, temporary lack of visual features, visual-lidar mapping, visual-lidar odometry},
   file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/8IGJJWEM/7139486.html:text/html;IEEE Xplore Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/EPQ9MNWZ/Zhang et Singh - 2015 - Visual-lidar odometry and mapping low-drift, robu.pdf:application/pdf}
  }

  @article{fuentes-pacheco_visual_2015,
   title = {Visual simultaneous localization and mapping: a survey},
   volume = {43},
   issn = {0269-2821, 1573-7462},
   url = {http://link.springer.com/10.1007/s10462-012-9365-8},
   doi = {10.1007/s10462-012-9365-8},
   shorttitle = {Visual simultaneous localization and mapping},
   pages = {55--81},
   number = {1},
   journaltitle = {Artificial Intelligence Review},
   author = {Fuentes-Pacheco, Jorge and Ruiz-Ascencio, José and Rendón-Mancha, Juan Manuel},
   urldate = {2017-03-29},
   date = {2015-01},
   langid = {english},
   file = {art%3A10.1007%2Fs10462-012-9365-8.pdf:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/P88QXNN2/art%3A10.1007%2Fs10462-012-9365-8.pdf:application/pdf}
   }

   @article{thrun_probabilistic_2002,
    title = {Probabilistic robotics},
    volume = {45},
    url = {http://dl.acm.org/citation.cfm?id=504754},
    pages = {52--57},
    number = {3},
    journaltitle = {Communications of the {ACM}},
    author = {Thrun, Sebastian},
    urldate = {2017-04-06},
    date = {2002},
    file = {Thrun_lo - p52-thrun.pdf:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/P3SJI44J/p52-thrun.pdf:application/pdf}
   }

   @inproceedings{mur-artal_probabilistic_2015,
    title = {Probabilistic Semi-Dense Mapping from Highly Accurate Feature-Based Monocular {SLAM}},
    isbn = {978-0-9923747-1-6},
    url = {http://www.roboticsproceedings.org/rss11/p41.pdf},
    doi = {10.15607/RSS.2015.XI.041},
    publisher = {Robotics: Science and Systems Foundation},
    author = {Mur-Artal, Raul and Tardos, Juan},
    urldate = {2017-05-02},
    date = {2015-07-13},
    file = {561cd04308ae6d17308ce267.pdf:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/4PHTSVC9/561cd04308ae6d17308ce267.pdf:application/pdf}
   }

   @article{durrant-whyte_simultaneous_2006,
    title = {Simultaneous localization and mapping: part I},
    volume = {13},
    issn = {1070-9932},
    doi = {10.1109/MRA.2006.1638022},
    shorttitle = {Simultaneous localization and mapping},
    abstract = {This paper describes the simultaneous localization and mapping ({SLAM}) problem and the essential methods for solving the {SLAM} problem and summarizes key implementations and demonstrations of the method. While there are still many practical issues to overcome, especially in more complex outdoor environments, the general {SLAM} method is now a well understood and established part of robotics. Another part of the tutorial summarized more recent works in addressing some of the remaining issues in {SLAM}, including computation, feature representation, and data association},
    pages = {99--110},
    number = {2},
    journaltitle = {{IEEE} Robotics Automation Magazine},
    author = {Durrant-Whyte, H. and Bailey, T.},
    date = {2006-06},
    keywords = {Artificial Intelligence, Bayesian methods, Buildings, History, Navigation, Particle filters, Robotics and automation, {SLAM} problem, Vehicles, mobile robots, path planning, simultaneous localization and mapping, simultaneous localization and mapping problem},
    file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/85XKIKNJ/1638022.html:text/html;IEEE Xplore Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/P2KF3H2T/Durrant-Whyte et Bailey - 2006 - Simultaneous localization and mapping part I.pdf:application/pdf}
   }

   @inproceedings{engel_lsd-slam:_2014,
    title = {{LSD}-{SLAM}: Large-scale direct monocular {SLAM}},
    url = {http://link.springer.com/chapter/10.1007/978-3-319-10605-2_54},
    shorttitle = {{LSD}-{SLAM}},
    pages = {834--849},
    booktitle = {European Conference on Computer Vision},
    publisher = {Springer},
    author = {Engel, Jakob and Schöps, Thomas and Cremers, Daniel},
    urldate = {2017-05-02},
    date = {2014},
    file = {engel14eccv.pdf:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/G3D47MG2/engel14eccv.pdf:application/pdf}
   }

   @inproceedings{liang_visual_2016,
    title = {Visual laser-{SLAM} in large-scale indoor environments},
    doi = {10.1109/ROBIO.2016.7866271},
    abstract = {Loop closure is a well-known problem in the research of laser based simultaneous localization and mapping, especially for applications in large-scale environments. The cumulative errors in the estimated pose and map make the loop detection difficult, no matter using particle filter-based or graph-based {SLAM} methods. Camera has the advantage of rich information but suffers from short distance and relative high computation burden. In this paper, we proposed a novel approach to address the loop closure problem in large-scale laser-{SLAMs}, where both laser and camera sensors are integrated. {ORB} features and bags-of-word were applied to obtain fast and robust performance of loop detection. The well-recognized {LRGC} {SLAM} framework and {SPA} optimization algorithm were then used to achieve the {SLAM}. Finally, several experiments in different large-scale environments were performed to verify the effectiveness of the proposed approach.},
    eventtitle = {2016 {IEEE} International Conference on Robotics and Biomimetics ({ROBIO})},
    pages = {19--24},
    booktitle = {2016 {IEEE} International Conference on Robotics and Biomimetics ({ROBIO})},
    author = {Liang, X. and Chen, H. and Li, Y. and Liu, Y.},
    date = {2016-12},
    keywords = {{LRGC} {SLAM} framework, {ORB} features, Robustness, {SLAM} (robots), {SPA} optimization algorithm, Visualization, camera, cameras, feature extraction, graph theory, graph-based {SLAM}, large-scale indoor environments, large-scale laser-{SLAM}, loop closure problem, optimisation, robot vision, simultaneous localization and mapping, visual laser-{SLAM}},
    file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/BPZ5HB7T/7866271.html:text/html;IEEE Xplore Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/HPK9F8VU/Liang et al. - 2016 - Visual laser-SLAM in large-scale indoor environmen.pdf:application/pdf}
   }

   @article{pomerleau_comparing_2013,
    title = {Comparing {ICP} variants on real-world data sets: Open-source library and experimental protocol},
    volume = {34},
    issn = {0929-5593, 1573-7527},
    url = {http://link.springer.com/10.1007/s10514-013-9327-2},
    doi = {10.1007/s10514-013-9327-2},
    shorttitle = {Comparing {ICP} variants on real-world data sets},
    pages = {133--148},
    number = {3},
    journaltitle = {Autonomous Robots},
    author = {Pomerleau, François and Colas, Francis and Siegwart, Roland and Magnenat, Stéphane},
    urldate = {2017-05-15},
    date = {2013-04},
    langid = {english},
    file = {art%3A10.1007%2Fs10514-013-9327-2.pdf:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/2MRCAD9Q/art%3A10.1007%2Fs10514-013-9327-2.pdf:application/pdf}
    }

    @collection{siciliano_springer_2008,
     location = {Berlin},
     title = {Springer handbook of robotics},
     isbn = {978-3-540-23957-4},
     pagetotal = {1611},
     publisher = {Springer},
     editor = {Siciliano, Bruno and Khatib, Oussama},
     date = {2008},
     note = {{OCLC}: ocn153562054},
     keywords = {robotics},
     file = {bok%3A978-3-540-30301-5.pdf:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/U4V8WPX9/bok%3A978-3-540-30301-5.pdf:application/pdf}
     }

     @inproceedings{lu_slam_2009,
      title = {{SLAM} estimation in dynamic outdoor environments: A review},
      url = {http://link.springer.com/chapter/10.1007/978-3-642-10817-4_25},
      shorttitle = {{SLAM} estimation in dynamic outdoor environments},
      pages = {255--267},
      booktitle = {International Conference on Intelligent Robotics and Applications},
      publisher = {Springer},
      author = {Lu, Zheyuan and Hu, Zhencheng and Uchimura, Keiichi},
      urldate = {2017-03-29},
      date = {2009},
      file = {LNAI 5928 - SLAM Estimation in Dynamic Outdoor Environments\: A Review - chp%3A10.1007%2F978-3-642-10817-4_25.pdf:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/KRZVMZXA/chp%3A10.1007%2F978-3-642-10817-4_25.pdf:application/pdf}
      }

      @article{zhang_low-drift_2017,
       title = {Low-drift and real-time lidar odometry and mapping},
       volume = {41},
       issn = {0929-5593, 1573-7527},
       url = {http://link.springer.com/10.1007/s10514-016-9548-2},
       doi = {10.1007/s10514-016-9548-2},
       pages = {401--416},
       number = {2},
       journaltitle = {Autonomous Robots},
       author = {Zhang, Ji and Singh, Sanjiv},
       urldate = {2017-05-15},
       date = {2017-02},
       langid = {english},
       file = {Low-drift and real-time lidar odometry and mapping - art%3A10.1007%2Fs10514-016-9548-2.pdf:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/8USK5X62/art%3A10.1007%2Fs10514-016-9548-2.pdf:application/pdf}
       }

       @article{howard_multirobot_2006,
        title = {Multirobot Simultaneous Localization and Mapping Using Manifold Representations},
        volume = {94},
        issn = {0018-9219},
        doi = {10.1109/JPROC.2006.876922},
        abstract = {This paper describes a novel representation for two-dimensional maps, and shows how this representation may be applied to the problem of multirobot simultaneous localization and mapping. We are inspired by the notion of a manifold, which takes maps out of the two-dimensional plane and onto a surface embedded in a higher-dimensional space. The key advantage of the manifold representation is self-consistency: when closing loops, manifold maps do not suffer from the "cross over" problem exhibited in planar maps. This self-consistency, in turn, facilitates a number of important capabilities, including autonomous exploration, search, and retro-traverse. It also supports a very robust form of loop closure, in which pairs of robots act collectively to confirm or reject possible correspondence points. In this paper, we develop the basic formalism of the manifold representation, show how this may be applied to the multirobot simultaneous localization and mapping problem, and present experimental results obtained from teams of up to four robots in environments ranging in size from 400 to 900 m2},
        pages = {1360--1369},
        number = {7},
        journaltitle = {Proceedings of the {IEEE}},
        author = {Howard, A. and Sukhatme, G. S. and Mataric, M. J.},
        date = {2006-07},
        keywords = {Computer science, Exploration and search, Laboratories, Propulsion, Robustness, Spirals, mobile robots, motion control, motion planning, multi-robot systems, multirobot systems, path planning, planar maps, position control, robot path mapping, simultaneous localization and mapping, simultaneous localization and mapping ({SLAM})},
        file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/J5A8T9EX/1677949.html:text/html;IEEE Xplore Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/898XW8ZS/Howard et al. - 2006 - Multirobot Simultaneous Localization and Mapping U.pdf:application/pdf}
       }

       @inproceedings{welle_optimization_2010,
        title = {Optimization techniques for laser-based 3D particle filter {SLAM}},
        doi = {10.1109/ROBOT.2010.5509992},
        abstract = {In recent years multiple simultaneous localization and mapping ({SLAM}) algorithms have been proposed, which address the challenges of 3D environments in combination with six degress of freedom in the robot position. Commonly, solutions based on scan-matching algorithms are applied. In contrast to these approaches, we propose to use a particle filter transferring the concept of the 2D Rao-Blackwellized particle filter {SLAM} to 3D. As filter input, 3D laser range data and odometry readings are obtained while the robot is in motion. The ground plane is estimated based on previously built map parts, thereby approaching the problem that not all degrees of freedom are covered by the odometry. To gain control of the high memory requirements for the particles' 3D map representations, we introduce a memory efficient search structure and adapt a technique to efficiently organize and share maps between particles. We evaluate our approach based on experimental results obtained by simulation as well as measurements of a real robot system.},
        eventtitle = {2010 {IEEE} International Conference on Robotics and Automation},
        pages = {3525--3530},
        booktitle = {2010 {IEEE} International Conference on Robotics and Automation},
        author = {Welle, J. and Schulz, D. and Bachran, T. and Cremers, A. B.},
        date = {2010-05},
        keywords = {Computer science, Gain control, Indoor environments, Laser theory, Particle filters, Robot sensing systems, Robotics and automation, {SLAM} (robots), {USA} Councils, distance measurement, laser-based 3D particle filter {SLAM}, mobile robots, odometry, optimisation, optimization techniques, particle filtering (numerical methods), robot position, search structure, simultaneous localization and mapping},
        file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/V5BHDJVF/5509992.html:text/html;IEEE Xplore Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/XKVPCKNM/Welle et al. - 2010 - Optimization techniques for laser-based 3D particl.pdf:application/pdf}
       }

       @inproceedings{azizi_3d_2016,
        title = {3D inertial algorithm of {SLAM} for using on {UAV}},
        doi = {10.1109/ICRoM.2016.7886833},
        abstract = {The simultaneous localization and mapping ({SLAM}) is a main problem in navigation of autonomous robots and solving it is interesting for researchers. Nowadays the {SLAM} technique is one of key part the navigation systems. In this paper, an efficient inertia {SLAM} algorithm has been presented for an unmanned aerial vehicle ({UAV}) or any airborne vehicle. The structure of mentioned inertial {SLAM} algorithm is appropriate for application in both the Range/Bearing and Bearing-only inertial sensors. This algorithm is independent of any external positioning information such as global positioning system ({GPS}) or any prepared data of terrain sensors. This work proposes a perfect system that improves the efficiency and accuracy of 3D inertial {SLAM} and over comes two main problems that less consideration is available about them in previous researches. First, it considers all of freedom degrees such as altitude, the latitude and longitude for {UAV}. Second, the algorithm based on inertial sensors is able to observe all of landmarks in various heights. Finally, using real flight data, the proposed algorithm is tested and the results showed desired performance of the algorithm for inertial system.},
        eventtitle = {2016 4th International Conference on Robotics and Mechatronics ({ICROM})},
        pages = {122--129},
        booktitle = {2016 4th International Conference on Robotics and Mechatronics ({ICROM})},
        author = {Azizi, A. and Nourisola, H. and Ghiasi, A. R.},
        date = {2016-10},
        keywords = {Algorithm design and analysis, Extended Kalman filter, Global Positioning System, Inertial navigation system, Mathematical model, Unmanned aerial vehicles, simultaneous localization and mapping},
        file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/K3W9WR2K/7886833.html:text/html;IEEE Xplore Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/2DVW7MXC/Azizi et al. - 2016 - 3D inertial algorithm of SLAM for using on UAV.pdf:application/pdf}
       }

       @inproceedings{fenwick_cooperative_2002,
        title = {Cooperative concurrent mapping and localization},
        volume = {2},
        doi = {10.1109/ROBOT.2002.1014804},
        abstract = {Autonomous vehicles require the ability to build maps of an unknown environment while concurrently using these maps for navigation. Current algorithms for this concurrent mapping and localization ({CML}) problem have been implemented for single vehicles, but do not account for extra positional information available when multiple vehicles operate simultaneously. Multiple vehicles have the potential to map an environment more quickly and robustly than a single vehicle. This paper presents a cooperative {CML} algorithm that merges sensor and navigation information from multiple autonomous vehicles. The algorithm presented is based on stochastic estimation and uses a feature-based approach to extract landmarks from the environment. The theoretical framework for the collaborative {CML} algorithm is presented, and a convergence theorem central to the cooperative {CML} problem. is proved for the first time. This theorem quantifies the performance gains of collaboration, allowing for determination of the number of cooperating vehicles required to accomplish a task. A simulated implementation of the collaborative {CML} algorithm demonstrates substantial performance improvement over non-cooperative {CML}.},
        eventtitle = {Proceedings 2002 {IEEE} International Conference on Robotics and Automation (Cat. No.02CH37292)},
        pages = {1810--1817 vol.2},
        booktitle = {Proceedings 2002 {IEEE} International Conference on Robotics and Automation (Cat. No.02CH37292)},
        author = {Fenwick, J. W. and Newman, P. M. and Leonard, J. J.},
        date = {2002},
        keywords = {Autonomous vehicles, {CML}, Collaboration, Data mining, Navigation, Remotely operated vehicles, Robustness, Stochastic processes, Vehicles, computerised navigation, convergence, convergence theorem, cooperative concurrent localization, cooperative concurrent mapping, cooperative systems, feature extraction, feature-based landmark extraction, localization, map building, mobile robots, multi-robot systems, simultaneous localization and mapping, stochastic estimation},
        file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/9NXJBK6B/1014804.html:text/html;IEEE Xplore Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/5DBZR6VC/Fenwick et al. - 2002 - Cooperative concurrent mapping and localization.pdf:application/pdf}
       }

       @inproceedings{mane_data_2016,
        title = {Data Acquisition analysis in {SLAM} applications},
        doi = {10.1109/ICACDOT.2016.7877605},
        abstract = {The Simultaneous Localization and Mapping ({SLAM}) problem for mobile robots aims at consistently building a map of an unknown environment while simultaneously determining its position or location within this map. From a control-theory viewpoint, it is somehow analogous to simultaneously estimating the states and output map of the system. In the robotic based engineering applications, {SLAM} is arguably considered a solved problem on a theoretical and conceptual level, but still it requires considerable maturity on a practical level [16][22]. The state-of-the-art {SLAM} algorithms require computationally powerful processors, expensive sensors with dense feature extraction and multiple sensors for uncertainty reduction [21]. An approach to the {SLAM} problem using minimal sensing information is still lacking in both theoretical and practical aspects. This paper highlights the data acquisition \& association issues with different sensors like odometric \& infra red sensors used in {SLAM} application due to addition of random Gaussian noise leading to errors \& uncertainty in mapping processes [17][22]. Simple filtering techniques using average filtering \& Kalman filtering have been implemented on the acquired data to go for comparative analysis of sensor performance \& its impact on {SLAM} process towards reduction in uncertainty or minimal shift in landmark extraction [19].},
        eventtitle = {2016 International Conference on Automatic Control and Dynamic Optimization Techniques ({ICACDOT})},
        pages = {339--343},
        booktitle = {2016 International Conference on Automatic Control and Dynamic Optimization Techniques ({ICACDOT})},
        author = {Mane, A. A. and Parihar, M. N. and Jadhav, S. P. and Gadre, R.},
        date = {2016-09},
        keywords = {Kalman filtering, Kalman filters, {SLAM}, Signal to noise ratio, Uncertainty, mapping, odometric, robotics, sharp {IR}, simultaneous localization and mapping},
        file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/ZRRKN3JZ/7877605.html:text/html;IEEE Xplore Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/H785R2VZ/Mane et al. - 2016 - Data Acquisition analysis in SLAM applications.pdf:application/pdf}
       }

       @article{parker_effect_2003,
        title = {The effect of heterogeneity in teams of 100+ mobile robots},
        volume = {2},
        url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.14.5382&rep=rep1&type=pdf},
        pages = {205--215},
        journaltitle = {Multi-Robot Systems},
        author = {Parker, Lynne E.},
        urldate = {2017-04-24},
        date = {2003},
        file = {Parker.dvi - download:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/4TD25UC7/download.pdf:application/pdf}
       }

       @article{dissanayake_solution_2001,
        title = {A solution to the simultaneous localization and map building ({SLAM}) problem},
        volume = {17},
        issn = {1042296X},
        url = {http://ieeexplore.ieee.org/document/938381/},
        doi = {10.1109/70.938381},
        pages = {229--241},
        number = {3},
        journaltitle = {{IEEE} Transactions on Robotics and Automation},
        author = {Dissanayake, M.W.M.G. and Newman, P. and Clark, S. and Durrant-Whyte, H.F. and Csorba, M.},
        urldate = {2017-02-13},
        date = {2001-06}
       }

       @article{murray_future_2003,
        title = {Future directions in control in an information-rich world},
        volume = {23},
        issn = {1066-033X},
        doi = {10.1109/MCS.2003.1188769},
        abstract = {The Panel on Future Directions in Control, Dynamics, and Systems was formed in April 2000 to provide a renewed vision of future challenges and opportunities in the control field, along with recommendations to government agencies, universities, and research organizations to ensure continued progress in areas of importance to the industrial and defense base. The panel released a report in April 2002, the intent of which is to raise the overall visibility of research in control, highlight its importance in applications of national interest, and indicate some of the key trends that are important for continued vitality of the field. After a brief introduction, we summarize the report, discuss its applications and education and outreach, and conclude with some recommendations.},
        pages = {20--33},
        number = {2},
        journaltitle = {{IEEE} Control Systems},
        author = {Murray, R. M. and Astrom, K. J. and Boyd, S. P. and Brockett, R. W. and Stein, G.},
        date = {2003-04},
        keywords = {Automatic control, Communication system control, Conferences, Control systems, Defense industry, Educational institutions, Electrical equipment industry, Government, Robots, Terrorism, Writing, aerospace, aerospace control, biology, chemical industry, chemical technology, communication networks, control education, control engineering, control engineering education, control field, future directions, intelligent machines, materials processing, materials science, medicine, report summary, robotics, technological forecasting, telecommunication networks, transportation},
        file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/7IWGG7V6/1188769.html:text/html;IEEE Xplore Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/3E8D43K7/Murray et al. - 2003 - Future directions in control in an information-ric.pdf:application/pdf}
       }

       @article{bailey_simultaneous_2006,
        title = {Simultaneous localization and mapping ({SLAM}): part {II}},
        volume = {13},
        issn = {1070-9932},
        doi = {10.1109/MRA.2006.1678144},
        shorttitle = {Simultaneous localization and mapping ({SLAM})},
        abstract = {This paper discusses the recursive Bayesian formulation of the simultaneous localization and mapping ({SLAM}) problem in which probability distributions or estimates of absolute or relative locations of landmarks and vehicle pose are obtained. The paper focuses on three key areas: computational complexity; data association; and environment representation},
        pages = {108--117},
        number = {3},
        journaltitle = {{IEEE} Robotics Automation Magazine},
        author = {Bailey, T. and Durrant-Whyte, H.},
        date = {2006-09},
        keywords = {Bayes methods, Bayesian methods, Computational efficiency, Delay estimation, Robotics and automation, Robustness, Uncertainty, Vehicles, computational complexity, data association, environment representation, mobile robot, mobile robots, path planning, probability distributions, recursive Bayesian formulation, simultaneous localization and mapping, statistical distributions, vehicle pose},
        file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/S2P7DAU5/1678144.html:text/html;IEEE Xplore Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/R6KDTK9X/Bailey et Durrant-Whyte - 2006 - Simultaneous localization and mapping (SLAM) part.pdf:application/pdf}
       }

       @inproceedings{gutmann_incremental_1999,
        title = {Incremental mapping of large cyclic environments},
        doi = {10.1109/CIRA.1999.810068},
        abstract = {Mobile robots can use geometric or topological maps of their environment to navigate reliably. Automatic creation of such maps is still an unrealized goal, especially in environments that have large cyclical structures. Drawing on recent techniques of global registration and correlation, we present a method, called local registration and global correlation, for reliable reconstruction of consistent global maps from dense range data. The method is attractive because it is incremental, producing an updated map with every new sensor input; and runs in constant time independent of the size of the map (except when closing large cycles). A real-time implementation and results are presented for several indoor environments},
        eventtitle = {1999 {IEEE} International Symposium on Computational Intelligence in Robotics and Automation, 1999. {CIRA} '99. Proceedings},
        pages = {318--325},
        booktitle = {1999 {IEEE} International Symposium on Computational Intelligence in Robotics and Automation, 1999. {CIRA} '99. Proceedings},
        author = {Gutmann, J. S. and Konolige, K.},
        date = {1999},
        keywords = {Indoor environments, Kalman filters, Navigation, Optical arrays, Real-time systems, Robot sensing systems, Sensor phenomena and characterization, Sonar measurements, User-generated content, correlation methods, cyclical structures, global correlation, global map reconstruction, incremental mapping, local registration, mobile robots, path planning, pose estimation, range data, stereo vision},
        file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/VWNGFNMF/810068.html:text/html;IEEE Xplore Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/3P9FVJCS/Gutmann et Konolige - 1999 - Incremental mapping of large cyclic environments.pdf:application/pdf}
       }

       @inproceedings{caruso_large-scale_2015,
        title = {Large-scale direct slam for omnidirectional cameras},
        url = {http://ieeexplore.ieee.org/abstract/document/7353366/},
        pages = {141--148},
        booktitle = {Intelligent Robots and Systems ({IROS}), 2015 {IEEE}/{RSJ} International Conference on},
        publisher = {{IEEE}},
        author = {Caruso, David and Engel, Jakob and Cremers, Daniel},
        urldate = {2017-05-02},
        date = {2015},
        file = {caruso2015_omni_lsdslam.pdf:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/9U32VQ9X/caruso2015_omni_lsdslam.pdf:application/pdf}
       }

       @inproceedings{clipp_parallel_2010,
        title = {Parallel, real-time visual {SLAM}},
        doi = {10.1109/IROS.2010.5653696},
        abstract = {In this paper we present a novel system for real-time, six degree of freedom visual simultaneous localization and mapping using a stereo camera as the only sensor. The system makes extensive use of parallelism both on the graphics processor and through multiple {CPU} threads. Working together these threads achieve real-time feature tracking, visual odometry, loop detection and global map correction using bundle adjustment. The resulting corrections are fed back into to the visual odometry system to limit its drift over long sequences. We demonstrate our system on a series videos from challenging indoor environments with moving occluders, visually homogenous regions with few features, scene parts with large changes in lighting and fast camera motion. The total system performs its task of global map building in real time including loop detection and bundle adjustment on typical office building scale scenes.},
        eventtitle = {2010 {IEEE}/{RSJ} International Conference on Intelligent Robots and Systems},
        pages = {3961--3968},
        booktitle = {2010 {IEEE}/{RSJ} International Conference on Intelligent Robots and Systems},
        author = {Clipp, B. and Lim, Jongwoo and Frahm, J. M. and Pollefeys, M.},
        date = {2010-10},
        keywords = {{SLAM} (robots), camera motion, cameras, computer graphic equipment, coprocessors, distance measurement, feature extraction, global map correction, graphics processor, image motion analysis, image sequence, image sequences, loop detection, multi-threading, multiple {CPU} thread, multiprocessing systems, occluder, parallel real-time visual {SLAM}, real-time feature tracking, robot vision, six degree of freedom, stereo camera, stereo image processing, video signal processing, visual odometry, visual simultaneous localization and mapping},
        file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/6CRP22UV/5653696.html:text/html;IEEE Xplore Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/5P4SPNVH/Clipp et al. - 2010 - Parallel, real-time visual SLAM.pdf:application/pdf}
       }

       @inproceedings{moosmann_velodyne_2011,
        title = {Velodyne {SLAM}},
        doi = {10.1109/IVS.2011.5940396},
        abstract = {Estimating a vehicles' own trajectory and generating precise maps of the environment are both important tasks for intelligent vehicles. Especially for the second task laser scanners are the sensor of choice as they provide precise range measurements. This work proposes an approach for simultaneous localization and mapping ({SLAM}) specifically designed for the Velodyne {HDL}-64E laser scanner which exhibits characteristics not present in most other systems. This comprises the continuous, spinning data acquisition and the relative high sensor noise. Together, these make standard {SLAM} approaches generate noisy maps and inaccurate trajectories. We show that it is possible to generate precise maps and localize therein in spite of not using wheel speed sensors or other information. The presented approach is evaluated on a novel, challenging 3D data set being made publicly available.},
        eventtitle = {2011 {IEEE} Intelligent Vehicles Symposium ({IV})},
        pages = {393--398},
        booktitle = {2011 {IEEE} Intelligent Vehicles Symposium ({IV})},
        author = {Moosmann, F. and Stiller, C.},
        date = {2011-06},
        keywords = {Iterative closest point algorithm, Measurement by laser beam, Pixel, {SLAM} (robots), Three dimensional displays, Trajectory, Vehicles, Velodyne {HDL}-64E laser scanner, Velodyne {SLAM}, data acquisition, image colour analysis, intelligent vehicles, optical scanners, path control, path planning, road vehicles, simultaneous localization and mapping, vehicle trajectory},
        file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/ZVFIWHJU/5940396.html:text/html;IEEE Xplore Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/CNDPIRUR/Moosmann et Stiller - 2011 - Velodyne SLAM.pdf:application/pdf}
       }

       @inproceedings{zia_comparative_2016,
        title = {Comparative design space exploration of dense and semi-dense {SLAM}},
        doi = {10.1109/ICRA.2016.7487261},
        abstract = {{SLAM} has matured significantly over the past few years, and is beginning to appear in serious commercial products. While new {SLAM} systems are being proposed at every conference, evaluation is often restricted to qualitative visualizations or accuracy estimation against a ground truth. This is due to the lack of benchmarking methodologies which can holistically and quantitatively evaluate these systems. Further investigation at the level of individual kernels and parameter spaces of {SLAM} pipelines is non-existent, which is absolutely essential for systems research and integration. We extend the recently introduced {SLAMBench} framework to allow comparing two state-of-the-art {SLAM} pipelines, namely {KinectFusion} and {LSD}-{SLAM}, along the metrics of accuracy, energy consumption, and processing frame rate on two different hardware platforms, namely a desktop and an embedded device. We also analyze the pipelines at the level of individual kernels and explore their algorithmic and hardware design spaces for the first time, yielding valuable insights.},
        eventtitle = {2016 {IEEE} International Conference on Robotics and Automation ({ICRA})},
        pages = {1292--1299},
        booktitle = {2016 {IEEE} International Conference on Robotics and Automation ({ICRA})},
        author = {Zia, M. Z. and Nardi, L. and Jack, A. and Vespa, E. and Bodin, B. and Kelly, P. H. J. and Davison, A. J.},
        date = {2016-05},
        keywords = {Estimation, Kernel, {KinectFusion}, {LSD}-{SLAM}, Optimization, {SLAM} (robots), {SLAMBench} framework, Three-dimensional displays, cameras, comparative design space exploration, dense {SLAM}, hardware design spaces, individual kernels, parameter spaces, pipelines, semidense {SLAM}, simultaneous localization and mapping},
        file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/TBCDUD74/7487261.html:text/html;IEEE Xplore Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/2XXR7X9F/Zia et al. - 2016 - Comparative design space exploration of dense and .pdf:application/pdf}
       }

       @article{pomerleau_review_2015,
        title = {A Review of Point Cloud Registration Algorithms for Mobile Robotics},
        volume = {4},
        issn = {1935-8253, 1935-8261},
        url = {http://ftp.nowpublishers.com/article/Details/ROB-035},
        doi = {10.1561/2300000035},
        abstract = {A Review of Point Cloud Registration Algorithms for Mobile Robotics},
        pages = {1--104},
        number = {1},
        journaltitle = {Foundations and Trends® in Robotics},
        shortjournal = {{ROB}},
        author = {Pomerleau, François and Colas, Francis and Siegwart, Roland},
        urldate = {2017-06-07},
        date = {2015-05-27},
        file = {2015_Pomerleau_FnTROB_Review.pdf:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/QXS7MTHS/2015_Pomerleau_FnTROB_Review.pdf:application/pdf}
       }

       @article{arun_least-squares_1987,
        title = {Least-Squares Fitting of Two 3-D Point Sets},
        volume = {{PAMI}-9},
        issn = {0162-8828},
        doi = {10.1109/TPAMI.1987.4767965},
        abstract = {Two point sets pi and p'i; i = 1, 2,..., N are related by p'i = Rpi + T + Ni, where R is a rotation matrix, T a translation vector, and Ni a noise vector. Given pi and p'i, we present an algorithm for finding the least-squares solution of R and T, which is based on the singular value decomposition ({SVD}) of a 3 Ã 3 matrix. This new algorithm is compared to two earlier algorithms with respect to computer time requirements.},
        pages = {698--700},
        number = {5},
        journaltitle = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
        author = {Arun, K. S. and Huang, T. S. and Blostein, S. D.},
        date = {1987-09},
        keywords = {Iterative algorithms, Motion estimation, Application software, Computer vision, Economic indicators, Matrix decomposition, Parameter estimation, Position measurement, Quaternions, Singular value decomposition, least-squares, quaternion},
        file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/9GG728JX/4767965.html:text/html;IEEE Xplore Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/R2XZZSFR/Arun et al. - 1987 - Least-Squares Fitting of Two 3-D Point Sets.pdf:application/pdf}
       }

       @article{horn_closed-form_1987,
        title = {Closed-form solution of absolute orientation using unit quaternions},
        volume = {4},
        url = {https://www.osapublishing.org/abstract.cfm?uri=josaa-4-4-629},
        pages = {629--642},
        number = {4},
        journaltitle = {{JOSA} A},
        author = {Horn, Berthold {KP}},
        urldate = {2017-06-08},
        date = {1987},
        file = {Closed-form solution of absolute orientation using unit quaternions - PDF-1.pdf:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/WGIWE36J/PDF-1.pdf:application/pdf}
       }

       @article{horn_closed_1988,
        title = {Closed form solutions of absolute orientation using orthonormal matrices},
        volume = {5},
        pages = {1127--1135},
        journaltitle = {Journal of the Optical Society},
        author = {Horn, Berthold {KP} and Hilden, Hugh M. and Negahdaripour, Shahrlar},
        date = {1988},
        file = {Closed-form solution of absolute orientation using orthonormal matrices - 53cf5fe30cf2f7e53cf7f07c.pdf:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/Q6DF2SI9/53cf5fe30cf2f7e53cf7f07c.pdf:application/pdf}
       }

       @article{bosse_map_2008,
        title = {Map Matching and Data Association for Large-Scale Two-dimensional Laser Scan-based {SLAM}},
        volume = {27},
        issn = {0278-3649},
        url = {http://ijr.sagepub.com/cgi/doi/10.1177/0278364908091366},
        doi = {10.1177/0278364908091366},
        pages = {667--691},
        number = {6},
        journaltitle = {The International Journal of Robotics Research},
        author = {Bosse, M. and Zlot, R.},
        urldate = {2017-06-08},
        date = {2008-06-01},
        langid = {english},
        file = {ijr_091366.dvi - 0278364908091366:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/AUHD6QBV/0278364908091366.pdf:application/pdf}
       }

       @article{chen_object_1992,
        title = {Object modelling by registration of multiple range images},
        volume = {10},
        url = {http://www.sciencedirect.com/science/article/pii/026288569290066C},
        pages = {145--155},
        number = {3},
        journaltitle = {Image and vision computing},
        author = {Chen, Yang and Medioni, Gérard},
        urldate = {2017-06-08},
        date = {1992},
        file = {PII\: 0262-8856(92)90066-C - 1-s2.0-026288569290066C-main.pdf:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/PJ2PKHRD/1-s2.0-026288569290066C-main.pdf:application/pdf}
       }

       @article{walker_estimating_1991,
        title = {Estimating 3-D location parameters using dual number quaternions},
        volume = {54},
        url = {http://www.sciencedirect.com/science/article/pii/104996609190036O},
        pages = {358--367},
        number = {3},
        journaltitle = {{CVGIP}: image understanding},
        author = {Walker, Michael W. and Shao, Lejun and Volz, Richard A.},
        urldate = {2017-06-08},
        date = {1991},
        file = {PII\: 1049-9660(91)90036-O - 1-s2.0-104996609190036O-main.pdf:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/NXFX8SZ7/1-s2.0-104996609190036O-main.pdf:application/pdf}
       }

       @article{lowe_distinctive_2004,
        title = {Distinctive image features from scale-invariant keypoints},
        volume = {60},
        url = {http://www.springerlink.com/index/H4L02691327PX768.pdf},
        pages = {91--110},
        number = {2},
        journaltitle = {International journal of computer vision},
        author = {Lowe, David G.},
        urldate = {2017-06-08},
        date = {2004},
        file = {Distinctive Image Features from Scale-Invariant Keypoints - art%3A10.1023%2FB%3AVISI.0000029664.99615.94.pdf:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/562ED33V/art%3A10.1023%2FB%3AVISI.0000029664.99615.94.pdf:application/pdf}
        }

        @article{reyes_registration_2007,
         title = {Registration of 3D Points Using Geometric Algebra and Tensor Voting},
         volume = {75},
         issn = {0920-5691, 1573-1405},
         url = {http://link.springer.com/10.1007/s11263-007-0038-z},
         doi = {10.1007/s11263-007-0038-z},
         pages = {351--369},
         number = {3},
         journaltitle = {International Journal of Computer Vision},
         author = {Reyes, Leo and Medioni, Gerard and Bayro, Eduardo},
         urldate = {2017-06-08},
         date = {2007-09-05},
         langid = {english},
         file = {VISI_11263_0038.tex - art%3A10.1007%2Fs11263-007-0038-z.pdf:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/F75UAA3F/art%3A10.1007%2Fs11263-007-0038-z.pdf:application/pdf}
         }

         @inproceedings{kummerle_g_2011,
          title = {g 2 o: A general framework for graph optimization},
          url = {http://ieeexplore.ieee.org/abstract/document/5979949/},
          shorttitle = {g 2 o},
          pages = {3607--3613},
          booktitle = {Robotics and Automation ({ICRA}), 2011 {IEEE} International Conference on},
          publisher = {{IEEE}},
          author = {Kümmerle, Rainer and Grisetti, Giorgio and Strasdat, Hauke and Konolige, Kurt and Burgard, Wolfram},
          urldate = {2017-07-04},
          date = {2011},
          file = {kuemmerle11icra.pdf:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/HU7GF4VK/kuemmerle11icra.pdf:application/pdf}
         }

         @article{chetverikov_robust_2005,
          title = {Robust Euclidean alignment of 3D point sets: the trimmed iterative closest point algorithm},
          volume = {23},
          issn = {02628856},
          url = {http://linkinghub.elsevier.com/retrieve/pii/S0262885604001179},
          doi = {10.1016/j.imavis.2004.05.007},
          shorttitle = {Robust Euclidean alignment of 3D point sets},
          pages = {299--309},
          number = {3},
          journaltitle = {Image and Vision Computing},
          author = {Chetverikov, Dmitry and Stepanov, Dmitry and Krsek, Pavel},
          urldate = {2017-07-10},
          date = {2005-03},
          langid = {english},
          file = {doi\:10.1016/j.imavis.2004.05.007 - 1-s2.0-S0262885604001179-main.pdf:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/FB42KG7Z/1-s2.0-S0262885604001179-main.pdf:application/pdf}
         }

         @article{bouaziz_sparse_2013,
          title = {Sparse Iterative Closest Point},
          volume = {32},
          issn = {1467-8659},
          url = {http://onlinelibrary.wiley.com/doi/10.1111/cgf.12178/abstract},
          doi = {10.1111/cgf.12178},
          abstract = {Rigid registration of two geometric data sets is essential in many applications, including robot navigation, surface reconstruction, and shape matching. Most commonly, variants of the Iterative Closest Point ({ICP}) algorithm are employed for this task. These methods alternate between closest point computations to establish correspondences between two data sets, and solving for the optimal transformation that brings these correspondences into alignment. A major difficulty for this approach is the sensitivity to outliers and missing data often observed in 3D scans. Most practical implementations of the {ICP} algorithm address this issue with a number of heuristics to prune or reweight correspondences. However, these heuristics can be unreliable and difficult to tune, which often requires substantial manual assistance. We propose a new formulation of the {ICP} algorithm that avoids these difficulties by formulating the registration optimization using sparsity inducing norms. Our new algorithm retains the simple structure of the {ICP} algorithm, while achieving superior registration results when dealing with outliers and incomplete data. The complete source code of our implementation is provided at http://lgg.epfl.ch/sparseicp.},
          pages = {113--123},
          number = {5},
          journaltitle = {Computer Graphics Forum},
          author = {Bouaziz, Sofien and Tagliasacchi, Andrea and Pauly, Mark},
          urldate = {2017-07-10},
          date = {2013-08-01},
          langid = {english},
          keywords = {I.3.5 [Computer Graphics]: Computational Geometry and Object Modeling—Geometric algorithms, languages, and systems},
          file = {Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/NQH7V7C7/Bouaziz et al. - 2013 - Sparse Iterative Closest Point.pdf:application/pdf;Snapshot:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/UFS55RBW/abstract.html:text/html}
         }

         @inproceedings{cunningham_fully_2012,
          title = {Fully distributed scalable smoothing and mapping with robust multi-robot data association},
          doi = {10.1109/ICRA.2012.6225356},
          abstract = {In this paper we focus on the multi-robot perception problem, and present an experimentally validated end-to-end multi-robot mapping framework, enabling individual robots in a team to see beyond their individual sensor horizons. The inference part of our system is the {DDF}-{SAM} algorithm [1], which provides a decentralized communication and inference scheme, but did not address the crucial issue of data association. One key contribution is a novel, {RANSAC}-based, approach for performing the between-robot data associations and initialization of relative frames of reference. We demonstrate this system with both data collected from real robot experiments, as well as in a large scale simulated experiment demonstrating the scalability of the proposed approach.},
          eventtitle = {2012 {IEEE} International Conference on Robotics and Automation},
          pages = {1093--1100},
          booktitle = {2012 {IEEE} International Conference on Robotics and Automation},
          author = {Cunningham, A. and Wurm, K. M. and Burgard, W. and Dellaert, F.},
          date = {2012-05},
          keywords = {Data mining, Optimization, Robot kinematics, Robustness, iterative methods, multi-robot systems, simultaneous localization and mapping, inference mechanisms, {DDF}-{SAM} algorithm, {RANSAC}-based approach, decentralized communication, distributed scalable mapping, distributed scalable smoothing, end-to-end multirobot mapping framework, inference scheme, multirobot perception problem, robust multirobot data association, sensor horizons, Transforms},
          file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/QRD8VFPX/6225356.html:text/html;IEEE Xplore Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/XJPE5BXF/Cunningham et al. - 2012 - Fully distributed scalable smoothing and mapping w.pdf:application/pdf}
         }

         @inproceedings{cunningham_ddf-sam_2013,
          title = {{DDF}-{SAM} 2.0: Consistent distributed smoothing and mapping},
          doi = {10.1109/ICRA.2013.6631323},
          shorttitle = {{DDF}-{SAM} 2.0},
          abstract = {This paper presents an consistent decentralized data fusion approach for robust multi-robot {SLAM} in dangerous, unknown environments. The {DDF}-{SAM} 2.0 approach extends our previous work by combining local and neighborhood information in a single, consistent augmented local map, without the overly conservative approach to avoiding information double-counting in the previous {DDF}-{SAM} algorithm. We introduce the anti-factor as a means to subtract information in graphical {SLAM} systems, and illustrate its use to both replace information in an incremental solver and to cancel out neighborhood information from shared summarized maps. This paper presents and compares three summarization techniques, with two exact approaches and an approximation. We evaluated the proposed system in a synthetic example and show the augmented local system and the associated summarization technique do not double-count information, while keeping performance tractable.},
          eventtitle = {2013 {IEEE} International Conference on Robotics and Automation},
          pages = {5220--5227},
          booktitle = {2013 {IEEE} International Conference on Robotics and Automation},
          author = {Cunningham, A. and Indelman, V. and Dellaert, F.},
          date = {2013-05},
          keywords = {{SLAM} (robots), multi-robot systems, simultaneous localization and mapping, {DDF}-{SAM} algorithm, decentralised control, sensor fusion, smoothing methods, {DDF}-{SAM} 2.0 approach, antifactor, augmented local system, consistent decentralized data fusion approach, consistent distributed smoothing and mapping, dangerous unknown environments, graphical {SLAM} systems, incremental solver, local information, neighborhood information, robust multirobot {SLAM}, shared summarized maps, single consistent augmented local map, Approximation methods, Silicon, Zirconium},
          file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/QUHVHHHC/6631323.html:text/html;IEEE Xplore Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/6VWJW56Z/Cunningham et al. - 2013 - DDF-SAM 2.0 Consistent distributed smoothing and .pdf:application/pdf}
         }

         @inproceedings{cesare_multi-uav_2015,
          title = {Multi-{UAV} exploration with limited communication and battery},
          doi = {10.1109/ICRA.2015.7139494},
          abstract = {We propose a multi-robot exploration algorithm that uses adaptive coordination to provide heterogeneous behavior. The key idea is to maximize the efficiency of exploring and mapping an unknown environment when a team is faced with unreliable communication and limited battery life (e.g., with aerial rotorcraft). The proposed algorithm utilizes four states: explore, meet, sacrifice, and relay. The explore state uses a frontier-based exploration algorithm, the meet state returns to the last known location of communication to share data, the sacrifice state sends the robot out to explore without consideration of remaining battery, and the relay state lands the robot until a meeting occurs. This approach allows robots to take on the role of a relay to improve communication between team members. In addition, the robots can “sacrifice” themselves by continuing to explore even when they do not have sufficient battery to return to the base station. We compare the performance of the proposed approach to state-of-the-art frontier-based exploration, and results show gains in explored area. The feasibility of components of the proposed approach is also demonstrated on a team of two custom-built quadcopters exploring an office environment.},
          eventtitle = {2015 {IEEE} International Conference on Robotics and Automation ({ICRA})},
          pages = {2230--2235},
          booktitle = {2015 {IEEE} International Conference on Robotics and Automation ({ICRA})},
          author = {Cesare, K. and Skeele, R. and Yoo, Soo-Hyun and Zhang, Yawei and Hollinger, G.},
          date = {2015-05},
          keywords = {Algorithm design and analysis, Robot kinematics, Robot sensing systems, multi-robot systems, autonomous aerial vehicles, adaptive coordination, aerial rotorcraft, base station, custom-built quadcopters, frontier-based exploration algorithm, heterogeneous behavior, limited battery life, {multiUAV} exploration, multirobot exploration algorithm, office environment, relay state, Base stations, Batteries, Relays},
          file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/W8FWVGK4/7139494.html:text/html;IEEE Xplore Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/2UNDZ4EE/Cesare et al. - 2015 - Multi-UAV exploration with limited communication a.pdf:application/pdf}
         }

         @inproceedings{cieslewski_map_2015,
          title = {Map {API} - scalable decentralized map building for robots},
          doi = {10.1109/ICRA.2015.7140075},
          abstract = {Large scale, long-term, distributed mapping is a core challenge to modern field robotics. Using the sensory output of multiple robots and fusing it in an efficient way enables the creation of globally accurate and consistent metric maps. To combine data from multiple agents into a global map, most existing approaches use a central entity that collects and manages the information from all agents. Often, the raw sensor data of one robot needs to be made available to processing algorithms on other agents due to the lack of computational resources on that robot. Unfortunately, network latency and low bandwidth in the field limit the generality of such an approach and make multi-robot map building a tedious task. In this paper, we present a distributed and decentralized back-end for concurrent and consistent robotic mapping. We propose a set of novel approaches that reduce the bandwidth usage and increase the effectiveness of inter-robot communication for distributed mapping. Instead of locking access to the map during operations, we define a version control system which allows concurrent and consistent access to the map data. Updates to the map are then shared asynchronously with agents which previously registered notifications. A technique for data lookup is provided by state-of-the-art algorithms from distributed computing. We validate our approach on real-world datasets and demonstrate the effectiveness of the proposed algorithms.},
          eventtitle = {2015 {IEEE} International Conference on Robotics and Automation ({ICRA})},
          pages = {6241--6247},
          booktitle = {2015 {IEEE} International Conference on Robotics and Automation ({ICRA})},
          author = {Cieslewski, T. and Lynen, S. and Dymczyk, M. and Magnenat, S. and Siegwart, R.},
          date = {2015-05},
          keywords = {Buildings, Robot sensing systems, multi-robot systems, robotic mapping, application program interfaces, configuration management, distributed processing, data lookup, decentralized back-end, distributed computing, distributed mapping, inter-robot communication, map {API}, multiple robot, multirobot map building, raw sensor data, scalable decentralized map, version control system, Bandwidth, Distributed databases, Protocols, Spatial indexes},
          file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/WSASN4NQ/7140075.html:text/html;IEEE Xplore Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/ENQJD73T/Cieslewski et al. - 2015 - Map API - scalable decentralized map building for .pdf:application/pdf}
         }

         @article{indelman_incremental_2016,
          title = {Incremental Distributed Inference from Arbitrary Poses and Unknown Data Association: Using Collaborating Robots to Establish a Common Reference},
          volume = {36},
          issn = {1066-033X},
          doi = {10.1109/MCS.2015.2512031},
          shorttitle = {Incremental Distributed Inference from Arbitrary Poses and Unknown Data Association},
          abstract = {High-accuracy localization is a fundamental capability that is essential for autonomous reliable operation in numerous applications, including autonomous driving, monitoring of an environmental phenomena, mapping, and tracking. The problem can be formulated as inference over the robot's state and possibly additional variables of interest based on incoming sensor measurements and a priori information, if such information exists. Moreover, in numerous applications, this inference problem has to be solved in real time, thus requiring computationally efficient inference methods.},
          pages = {41--74},
          number = {2},
          journaltitle = {{IEEE} Control Systems},
          author = {Indelman, V. and Nelson, E. and Dong, J. and Michael, N. and Dellaert, F.},
          date = {2016-04},
          keywords = {Computational efficiency, Real-time systems, Robot sensing systems, Trajectory, data association, multi-robot systems, simultaneous localization and mapping, inference mechanisms, sensor fusion, Distributed databases, control engineering computing, collaborating robots, high-accuracy localization, incremental distributed inference, sensor measurements, Probabilistic logic},
          file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/3TTV7B6J/7434165.html:text/html;IEEE Xplore Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/AFFACQUE/Indelman et al. - 2016 - Incremental Distributed Inference from Arbitrary P.pdf:application/pdf}
         }

         @inproceedings{walls_cooperative_2015,
          title = {Cooperative localization by factor composition over a faulty low-bandwidth communication channel},
          doi = {10.1109/ICRA.2015.7139030},
          abstract = {This paper reports on an underwater cooperative localization algorithm for faulty low-bandwidth communication channels based on a factor graph estimation framework. Vehicles measure the one-way-travel-time ({OWTT}) of acoustic broadcasts to obtain a relative range observation to the transmitting vehicle. We present a method to robustly share locally observed sensor data across the network by exploiting odometry factor composition. Our algorithm calls on approximate marginalization techniques to compute a compact set of informative factors that enable local navigation data to be shared efficiently. We provide results from a real-time implementation of our algorithm using two autonomous underwater vehicles and a surface vehicle.},
          eventtitle = {2015 {IEEE} International Conference on Robotics and Automation ({ICRA})},
          pages = {401--408},
          booktitle = {2015 {IEEE} International Conference on Robotics and Automation ({ICRA})},
          author = {Walls, J. M. and Cunningham, A. G. and Eustice, R. M.},
          date = {2015-05},
          keywords = {Acoustics, Global Positioning System, Robustness, Vehicles, autonomous underwater vehicles, distance measurement, graph theory, mobile robots, multi-robot systems, path planning, Approximation methods, approximation theory, telecommunication channels, acoustic broadcasts, approximate marginalization techniques, factor graph estimation framework, faulty low-bandwidth communication channel, informative factors, locally observed sensor data sharing, odometry factor composition, one-way-travel-time measurement, relative range observation, surface vehicle, underwater cooperative localization algorithm, Approximation algorithms},
          file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/QTGPIMIE/7139030.html:text/html;IEEE Xplore Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/77JUFCDT/Walls et al. - 2015 - Cooperative localization by factor composition ove.pdf:application/pdf}
         }

         @inproceedings{cunningham_ddf-sam:_2010,
          title = {{DDF}-{SAM}: Fully distributed {SLAM} using Constrained Factor Graphs},
          doi = {10.1109/IROS.2010.5652875},
          shorttitle = {{DDF}-{SAM}},
          abstract = {We address the problem of multi-robot distributed {SLAM} with an extended Smoothing and Mapping ({SAM}) approach to implement Decentralized Data Fusion ({DDF}). We present {DDF}-{SAM}, a novel method for efficiently and robustly distributing map information across a team of robots, to achieve scalability in computational cost and in communication bandwidth and robustness to node failure and to changes in network topology. {DDF}-{SAM} consists of three modules: (1) a local optimization module to execute single-robot {SAM} and condense the local graph; (2) a communication module to collect and propagate condensed local graphs to other robots, and (3) a neighborhood graph optimizer module to combine local graphs into maps describing the neighborhood of a robot. We demonstrate scalability and robustness through a simulated example, in which inference is consistently faster than a comparable naive approach.},
          eventtitle = {2010 {IEEE}/{RSJ} International Conference on Intelligent Robots and Systems},
          pages = {3025--3030},
          booktitle = {2010 {IEEE}/{RSJ} International Conference on Intelligent Robots and Systems},
          author = {Cunningham, A. and Paluri, M. and Dellaert, F.},
          date = {2010-10},
          keywords = {{SLAM} (robots), graph theory, multi-robot systems, optimisation, sensor fusion, distributed control, network topology, {DDF}-{SAM}, communication bandwidth, computational cost, condensed local graphs, constrained factor graphs, decentralized data fusion, fully distributed {SLAM}, local optimization module, multirobot distributed {SLAM}, neighborhood graph optimizer module, robustly distributing map information, single robot {SAM}, smoothing and mapping approach},
          file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/PN7IDUNI/5652875.html:text/html;IEEE Xplore Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/QPGSMHEK/Cunningham et al. - 2010 - DDF-SAM Fully distributed SLAM using Constrained .pdf:application/pdf}
         }

         @inproceedings{bailey_decentralised_2011,
          title = {Decentralised cooperative localisation for heterogeneous teams of mobile robots},
          doi = {10.1109/ICRA.2011.5979850},
          abstract = {This paper presents a distributed algorithm for performing joint localisation of a team of robots. The mobile robots have heterogeneous sensing capabilities, with some having high quality inertial and exteroceptive sensing, while others have only low quality sensing or none at all. By sharing information, a combined estimate of all robot poses is obtained. Inter-robot range-bearing measurements provide the mechanism for transferring pose information from well-localised vehicles to those less capable. In our proposed formulation, high frequency egocentric data (e.g., odometry, {IMU}, {GPS}) is fused locally on each platform. This is the distributed part of the algorithm. Inter-robot measurements, and accompanying state estimates, are communicated to a central server, which generates an optimal minimum mean-squared estimate of all robot poses. This server is easily duplicated for full redundant decentralisation. Communication and computation are efficient due to the sparseness properties of the information-form Gaussian representation. A team of three indoor mobile robots equipped with lasers, odometry and inertial sensing provides experimental verification of the algorithms effectiveness in combining location information.},
          eventtitle = {2011 {IEEE} International Conference on Robotics and Automation},
          pages = {2859--2865},
          booktitle = {2011 {IEEE} International Conference on Robotics and Automation},
          author = {Bailey, T. and Bryson, M. and Mu, H. and Vial, J. and {McCalman}, L. and Durrant-Whyte, H.},
          date = {2011-05},
          keywords = {Estimation, Gaussian processes, Robot sensing systems, cooperative systems, mobile robots, multi-robot systems, odometry, path planning, pose estimation, decentralised control, distributed algorithms, inertial navigation, decentralised cooperative localisation, distributed algorithm, exteroceptive sensing, heterogeneous mobile robot teams, heterogeneous sensing capabilities, indoor mobile robots, inertial sensing, information sharing, information-form Gaussian representation, interrobot measurements, joint localisation, optimal minimum mean-squared estimation, redundant decentralisation, robot pose estimation, Joints, Markov processes, Servers},
          file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/Z5W9VR2N/5979850.html:text/html;IEEE Xplore Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/RKHXCMJT/Bailey et al. - 2011 - Decentralised cooperative localisation for heterog.pdf:application/pdf}
         }

         @inproceedings{bahr_consistent_2009,
          title = {Consistent cooperative localization},
          doi = {10.1109/ROBOT.2009.5152859},
          abstract = {In cooperative navigation, teams of mobile robots obtain range and/or angle measurements to each other and dead-reckoning information to help each other navigate more accurately. One typical approach is moving baseline navigation, in which multiple Autonomous Underwater Vehicles ({AUVs}) exchange range measurements using acoustic modems to perform mobile trilateration. While the sharing of information between vehicles can be highly beneficial, exchanging measurements and state estimates can also be dangerous because of the risk of measurements being used by a vehicle more than once; such data re-use leads to inconsistent (overconfident) estimates, making data association and outlier rejection more difficult and divergence more likely. In this paper, we present a technique for the consistent cooperative localization of multiple {AUVs} performing mobile trilateration. Each {AUV} establishes a bank of filters, performing careful bookkeeping to track the origins of measurements and prevent the use any of the measurements more than once. The multiple estimates are combined in a consistent manner, yielding conservative covariance estimates. The technique is illustrated using simulation results. The new method is compared side-by-side with a naive approach that does not keep track of the origins of measurements, illustrating that the new method keeps conservative covariance bounds whereas state estimates obtained with the naive approach become overconfident and diverge.},
          eventtitle = {2009 {IEEE} International Conference on Robotics and Automation},
          pages = {3415--3422},
          booktitle = {2009 {IEEE} International Conference on Robotics and Automation},
          author = {Bahr, A. and Walter, M. R. and Leonard, J. J.},
          date = {2009-05},
          keywords = {Navigation, Remotely operated vehicles, data association, mobile robot, mobile robots, sensor fusion, acoustic devices, covariance analysis, underwater vehicles, acoustic modem, angle measurement, consistent cooperative localization, covariance estimation, dead reckoning, mobile trilateration, multiple autonomous underwater vehicle, outlier rejection, range measurement, state estimation, Acoustic measurements, Goniometers, Performance evaluation, Underwater acoustics, Yield estimation, Cooperative Localization, Cooperative Navigation},
          file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/FRZC3D23/5152859.html:text/html;IEEE Xplore Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/D48AMEJW/Bahr et al. - 2009 - Consistent cooperative localization.pdf:application/pdf}
         }

         @inproceedings{andersson_c-sam:_2008,
          title = {C-{SAM}: Multi-Robot {SLAM} using square root information smoothing},
          doi = {10.1109/ROBOT.2008.4543634},
          shorttitle = {C-{SAM}},
          abstract = {This paper presents collaborative smoothing and mapping (C-{SAM}) as a viable approach to the multi-robot map- alignment problem. This method enables a team of robots to build joint maps with or without initial knowledge of their relative poses. To accomplish the simultaneous localization and mapping this method uses square root information smoothing ({SRIS}). In contrast to traditional extended Kalman filter ({EKF}) methods the smoothing does not exclude any information and is therefore also better equipped to deal with non-linear process and measurement models. The method proposed does not require the collaborative robots to have initial correspondence. The key contribution of this work is an optimal smoothing algorithm for merging maps that are created by different robots independently or in groups. The method not only joins maps from different robots, it also recovers the complete robot trajectory for each robot involved in the map joining. It is also shown how data association between duplicate features is done and how this reduces uncertainty in the complete map. Two simulated scenarios are presented where the C-{SAM} algorithm is applied on two individually created maps. One basically joins two maps resulting in a large map while the other shows a scenario where sensor extension is carried out.},
          eventtitle = {2008 {IEEE} International Conference on Robotics and Automation},
          pages = {2798--2805},
          booktitle = {2008 {IEEE} International Conference on Robotics and Automation},
          author = {Andersson, L. A. A. and Nygards, J.},
          date = {2008-05},
          keywords = {Robot sensing systems, Robotics and automation, Robustness, {SLAM} (robots), Trajectory, {USA} Councils, multi-robot systems, position control, simultaneous localization and mapping, smoothing methods, Bandwidth, extended Kalman filter method, multi-robot {SLAM}, robot trajectory, simultaneous localization and mapping method, square root information smoothing, Collaborative work, Connectors},
          file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/TBR3TUV9/4543634.html:text/html;IEEE Xplore Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/EETDV2F7/Andersson et Nygards - 2008 - C-SAM Multi-Robot SLAM using square root informat.pdf:application/pdf}
         }

         @inproceedings{kim_multiple_2010,
          title = {Multiple relative pose graphs for robust cooperative mapping},
          doi = {10.1109/ROBOT.2010.5509154},
          abstract = {This paper describes a new algorithm for cooperative and persistent simultaneous localization and mapping ({SLAM}) using multiple robots. Recent pose graph representations have proven very successful for single robot mapping and localization. Among these methods, incremental smoothing and mapping ({iSAM}) gives an exact incremental solution to the {SLAM} problem by solving a full nonlinear optimization problem in real-time. In this paper, we present a novel extension to {iSAM} to facilitate online multi-robot mapping based on multiple pose graphs. Our main contribution is a relative formulation of the relationship between multiple pose graphs that avoids the initialization problem and leads to an efficient solution when compared to a completely global formulation. The relative pose graphs are optimized together to provide a globally consistent multi-robot solution. Efficient access to covariances at any time for relative parameters is provided through {iSAM}, facilitating data association and loop closing. The performance of the technique is illustrated on various data sets including a publicly available multi-robot data set. Further evaluation is performed in a collaborative helicopter and ground robot experiment.},
          eventtitle = {2010 {IEEE} International Conference on Robotics and Automation},
          pages = {3185--3192},
          booktitle = {2010 {IEEE} International Conference on Robotics and Automation},
          author = {Kim, B. and Kaess, M. and Fletcher, L. and Leonard, J. and Bachrach, A. and Roy, N. and Teller, S.},
          date = {2010-05},
          keywords = {Computational efficiency, Orbital robotics, Robot sensing systems, Robotics and automation, Robustness, {SLAM}, {SLAM} (robots), Space technology, {USA} Councils, data association, graph theory, mobile robot, mobile robots, multi-robot systems, simultaneous localization and mapping, sensor fusion, smoothing methods, closed loop systems, nonlinear programming, collaborative helicopter, ground robot experiment, {iSAM}, incremental smoothing and mapping, loop closing, multirobot solution, nonlinear optimization, online multirobot mapping, pose graph representation, relative pose graph, robust cooperative mapping, Optimization methods},
          file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/P5AV7BDA/5509154.html:text/html;IEEE Xplore Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/VASSEXZ9/Kim et al. - 2010 - Multiple relative pose graphs for robust cooperati.pdf:application/pdf}
         }

         @inproceedings{carlone_rao-blackwellized_2010,
          title = {Rao-Blackwellized Particle Filters multi robot {SLAM} with unknown initial correspondences and limited communication},
          doi = {10.1109/ROBOT.2010.5509307},
          abstract = {Multi robot systems are envisioned to play an important role in many robotic applications. A main prerequisite for a team deployed in a wide unknown area is the capability of autonomously navigate, exploiting the information acquired through the on-line estimation of both robot poses and surrounding environment model, according to Simultaneous Localization And Mapping ({SLAM}) framework. As team coordination is improved, distributed techniques for filtering are required in order to enhance autonomous exploration and large scale {SLAM} increasing both efficiency and robustness of operation. Although Rao-Blackwellized Particle Filters ({RBPF}) have been demonstrated to be an effective solution to the problem of single robot {SLAM}, few extensions to teams of robots exist, and these approaches are characterized by strict assumptions on both communication bandwidth and prior knowledge on relative poses of the teammates. In the present paper we address the problem of multi robot {SLAM} in the case of limited communication and unknown relative initial poses. Starting from the well established single robot {RBPF}-{SLAM}, we propose a simple technique which jointly estimates {SLAM} posterior of the robots by fusing the prioceptive and the eteroceptive information acquired by each teammate. The approach intrinsically reduces the amount of data to be exchanged among the robots, while taking into account the uncertainty in relative pose measurements. Moreover it can be naturally extended to different communication technologies (bluetooth, {RFId}, wifi, etc.) regardless their sensing range. The proposed approach is validated through experimental test.},
          eventtitle = {2010 {IEEE} International Conference on Robotics and Automation},
          pages = {243--249},
          booktitle = {2010 {IEEE} International Conference on Robotics and Automation},
          author = {Carlone, L. and Ng, M. Kaouk and Du, J. and Bona, B. and Indri, M.},
          date = {2010-05},
          keywords = {Filtering, Navigation, Particle filters, Robot kinematics, Robot sensing systems, Robustness, {SLAM} (robots), mobile robots, multi-robot systems, particle filtering (numerical methods), simultaneous localization and mapping, Bandwidth, Rao-Blackwellized particle filter, eteroceptive information, multirobot {SLAM}, prioceptive information, relative pose measurement, single robot {RBPF}-{SLAM}, Communications technology, Large-scale systems},
          file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/SA8AANU7/5509307.html:text/html;IEEE Xplore Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/SDD7Z547/Carlone et al. - 2010 - Rao-Blackwellized Particle Filters multi robot SLA.pdf:application/pdf}
         }

         @article{howard_multi-robot_2006,
          title = {Multi-robot Simultaneous Localization and Mapping using Particle Filters},
          volume = {25},
          issn = {0278-3649, 1741-3176},
          url = {http://journals.sagepub.com/doi/10.1177/0278364906072250},
          doi = {10.1177/0278364906072250},
          pages = {1243--1256},
          number = {12},
          journaltitle = {The International Journal of Robotics Research},
          author = {Howard, Andrew},
          urldate = {2017-07-11},
          date = {2006-12},
          langid = {english},
          file = {0278364906072250:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/5K579MIJ/0278364906072250.pdf:application/pdf}
         }

         @inproceedings{ni_multi-level_2010,
          title = {Multi-level submap based {SLAM} using nested dissection},
          doi = {10.1109/IROS.2010.5650197},
          abstract = {We propose a novel batch algorithm for {SLAM} problems that distributes the workload in a hierarchical way. We show that the original {SLAM} graph can be recursively partitioned into multiple-level submaps using the nested dissection algorithm, which leads to the cluster tree, a powerful graph representation. By employing the nested dissection algorithm, our algorithm greatly minimizes the dependencies between two subtrees, and the optimization of the original {SLAM} graph can be done using a bottom-up inference along the corresponding cluster tree. To speed up the computation, we also introduce a base node for each submap and use it to represent the rigid transformation of the submap in the global coordinate frame. As a result, the optimization moves the base nodes rather than the actual submap variables. We demonstrate that our algorithm is not only exact but also much faster than alternative approaches in both simulations and real-world experiments.},
          eventtitle = {2010 {IEEE}/{RSJ} International Conference on Intelligent Robots and Systems},
          pages = {2558--2565},
          booktitle = {2010 {IEEE}/{RSJ} International Conference on Intelligent Robots and Systems},
          author = {Ni, K. and Dellaert, F.},
          date = {2010-10},
          keywords = {{SLAM} (robots), optimisation, simultaneous localization and mapping, inference mechanisms, trees (mathematics), {SLAM} graph optimization, bottom up inference, cluster tree, multilevel submap, nested dissection, rigid transformation},
          file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/XTS7N5JD/5650197.html:text/html;IEEE Xplore Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/Z5PES2G7/Ni et Dellaert - 2010 - Multi-level submap based SLAM using nested dissect.pdf:application/pdf}
         }

         @article{neira_data_2001,
          title = {Data association in stochastic mapping using the joint compatibility test},
          volume = {17},
          issn = {1042-296X},
          doi = {10.1109/70.976019},
          abstract = {In this paper, we address the problem of robust data association for simultaneous vehicle localization and map building. We show that the classical gated nearest neighbor approach, which considers each matching between sensor observations and features independently, ignores the fact that measurement prediction errors are correlated. This leads to easily accepting incorrect matchings when clutter or vehicle errors increase. We propose a new measurement of the joint compatibility of a set of pairings that successfully rejects spurious matchings. We show experimentally that this restrictive criterion can be used to efficiently search for the best solution to data association. Unlike the nearest neighbor, this method provides a robust solution in complex situations, such as cluttered environments or when revisiting previously mapped regions},
          pages = {890--897},
          number = {6},
          journaltitle = {{IEEE} Transactions on Robotics and Automation},
          author = {Neira, J. and Tardos, J. D.},
          date = {2001-12},
          keywords = {Navigation, Robustness, Sensor phenomena and characterization, Stochastic processes, Testing, Vehicles, map building, mobile robots, path planning, computational geometry, Mahalanobis distance, gated nearest neighbor, joint compatibility, nearest neighbor, robust data association, vehicle localization, Nearest neighbor searches, Neural networks, Technological innovation},
          file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/26HTS2M9/976019.html:text/html;IEEE Xplore Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/U5XNNHZF/Neira et Tardos - 2001 - Data association in stochastic mapping using the j.pdf:application/pdf}
         }

         @inproceedings{aragues_consistent_2011,
          title = {Consistent data association in multi-robot systems with limited communications},
          url = {https://books.google.com/books?hl=en&lr=&id=q9TxCwAAQBAJ&oi=fnd&pg=PA97&dq=%22failures.+Information+is+exchanged+exclusively%22+%22and+visual+methods+for+feature-based+maps+%5B12%5D,+%5B17%5D.%22+%22estimates+of+a+common+element.+It+is+of+high%22+%22simultaneously.+The+Combined+Constraint%22+&ots=75k7Gmt9_8&sig=3NJp7_DxIdvtKRO-3uQoVH15_E4},
           pages = {97--104},
           booktitle = {Robotics: Science and Systems},
           author = {Aragues, Rosario and Montijano, Eduardo and Sagues, Carlos},
           urldate = {2017-07-11},
           date = {2011},
           file = {p13.pdf:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/CE9MA99K/p13.pdf:application/pdf}
          }

          @article{fischler_random_1981,
           title = {Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography},
           volume = {24},
           url = {http://dl.acm.org/citation.cfm?id=358692},
           shorttitle = {Random sample consensus},
           pages = {381--395},
           number = {6},
           journaltitle = {Communications of the {ACM}},
           author = {Fischler, Martin A. and Bolles, Robert C.},
           urldate = {2017-07-11},
           date = {1981},
           file = {Random sample consensus\: a paradigm for model fitting with applications to image analysis and automated cartography - p381-fischler.pdf:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/XAJT3B2N/p381-fischler.pdf:application/pdf}
          }

          @inproceedings{ni_groupsac:_2009,
           title = {{GroupSAC}: Efficient consensus in the presence of groupings},
           doi = {10.1109/ICCV.2009.5459241},
           shorttitle = {{GroupSAC}},
           abstract = {We present a novel variant of the {RANSAC} algorithm that is much more efficient, in particular when dealing with problems with low inlier ratios. Our algorithm assumes that there exists some grouping in the data, based on which we introduce a new binomial mixture model rather than the simple binomial model as used in {RANSAC}. We prove that in the new model it is more efficient to sample data from a smaller numbers of groups and groups with more tentative correspondences, which leads to a new sampling procedure that uses progressive numbers of groups. We demonstrate our algorithm on two classical geometric vision problems: wide-baseline matching and camera resectioning. The experiments show that the algorithm serves as a general framework that works well with three possible grouping strategies investigated in this paper, including a novel optical flow based clustering approach. The results show that our algorithm is able to achieve a significant performance gain compared to the standard {RANSAC} and {PROSAC}.},
           eventtitle = {2009 {IEEE} 12th International Conference on Computer Vision},
           pages = {2193--2200},
           booktitle = {2009 {IEEE} 12th International Conference on Computer Vision},
           author = {Ni, Kai and Jin, Hailin and Dellaert, F.},
           date = {2009-09},
           keywords = {Testing, cameras, image matching, image motion analysis, image sequences, iterative methods, Computer vision, image sampling, pattern clustering, {GroupSAC}, {RANSAC} algorithm, binomial mixture model, camera resectioning, geometric vision problem, optical flow based clustering, sampling procedure, wide-baseline matching, Clustering algorithms, Geometrical optics, Image segmentation, Internet, Performance gain, Sampling methods},
           file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/QXWNIIRS/5459241.html:text/html;IEEE Xplore Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/4M7ZD4H4/Ni et al. - 2009 - GroupSAC Efficient consensus in the presence of g.pdf:application/pdf}
          }

          @inproceedings{chum_matching_2005,
           title = {Matching with {PROSAC} - progressive sample consensus},
           volume = {1},
           doi = {10.1109/CVPR.2005.221},
           abstract = {A new robust matching method is proposed. The progressive sample consensus ({PROSAC}) algorithm exploits the linear ordering defined on the set of correspondences by a similarity function used in establishing tentative correspondences. Unlike {RANSAC}, which treats all correspondences equally and draws random samples uniformly from the full set, {PROSAC} samples are drawn from progressively larger sets of top-ranked correspondences. Under the mild assumption that the similarity measure predicts correctness of a match better than random guessing, we show that {PROSAC} achieves large computational savings. Experiments demonstrate it is often significantly faster (up to more than hundred times) than {RANSAC}. For the derived size of the sampled set of correspondences as a function of the number of samples already drawn, {PROSAC} converges towards {RANSAC} in the worst case. The power of the method is demonstrated on wide-baseline matching problems.},
           eventtitle = {2005 {IEEE} Computer Society Conference on Computer Vision and Pattern Recognition ({CVPR}'05)},
           pages = {220--226 vol. 1},
           booktitle = {2005 {IEEE} Computer Society Conference on Computer Vision and Pattern Recognition ({CVPR}'05)},
           author = {Chum, O. and Matas, J.},
           date = {2005-06},
           keywords = {Motion estimation, Robustness, Testing, image matching, stereo vision, Computer vision, image sampling, wide-baseline matching, {PROSAC} algorithm, progressive sample consensus, Cybernetics, Image converters, Image retrieval, Pattern matching, Solid modeling},
           file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/T3B6VBRN/1467271.html:text/html;IEEE Xplore Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/M69J5PPE/Chum et Matas - 2005 - Matching with PROSAC - progressive sample consensu.pdf:application/pdf}
          }

          @article{kaess_isam:_2008,
           title = {{iSAM}: Incremental Smoothing and Mapping},
           volume = {24},
           issn = {1552-3098},
           doi = {10.1109/TRO.2008.2006706},
           shorttitle = {{iSAM}},
           abstract = {In this paper, we present incremental smoothing and mapping ({iSAM}), which is a novel approach to the simultaneous localization and mapping problem that is based on fast incremental matrix factorization. {iSAM} provides an efficient and exact solution by updating a {QR} factorization of the naturally sparse smoothing information matrix, thereby recalculating only those matrix entries that actually change. {iSAM} is efficient even for robot trajectories with many loops as it avoids unnecessary fill-in in the factor matrix by periodic variable reordering. Also, to enable data association in real time, we provide efficient algorithms to access the estimation uncertainties of interest based on the factored information matrix. We systematically evaluate the different components of {iSAM} as well as the overall algorithm using various simulated and real-world datasets for both landmark and pose-only settings.},
           pages = {1365--1378},
           number = {6},
           journaltitle = {{IEEE} Transactions on Robotics},
           author = {Kaess, M. and Ranganathan, A. and Dellaert, F.},
           date = {2008-12},
           keywords = {{SLAM} (robots), data association, localization, mapping, mobile robots, position control, simultaneous localization and mapping ({SLAM}), simultaneous localization and mapping problem, Matrix decomposition, sensor fusion, smoothing methods, robot trajectory, sparse matrices, incremental matrix factorization, incremental smoothing-mapping, periodic variable reordering, sparse smoothing information matrix, uncertainty estimation, nonlinear estimation, smoothing},
           file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/C4XJBHW5/4682731.html:text/html;IEEE Xplore Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/67J9RHJ3/Kaess et al. - 2008 - iSAM Incremental Smoothing and Mapping.pdf:application/pdf}
          }

          @incollection{shewchuk_triangle:_1996,
           title = {Triangle: Engineering a 2D quality mesh generator and Delaunay triangulator},
           url = {https://link.springer.com/chapter/10.1007/BFb0014497},
           shorttitle = {Triangle},
           pages = {203--222},
           booktitle = {Applied computational geometry towards geometric engineering},
           publisher = {Springer},
           author = {Shewchuk, Jonathan Richard},
           urldate = {2017-07-11},
           date = {1996},
           file = {Triangle\: Engineering a 2D quality mesh generator and Delaunay triangulator - BFb0014497.pdf:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/5DIPCDDM/10.1007BFb0014497.pdf:application/pdf}
          }

          @article{kaess_isam2:_2012,
           title = {{iSAM}2: Incremental smoothing and mapping using the Bayes tree},
           volume = {31},
           issn = {0278-3649, 1741-3176},
           url = {http://journals.sagepub.com/doi/10.1177/0278364911430419},
           doi = {10.1177/0278364911430419},
           shorttitle = {{iSAM}2},
           pages = {216--235},
           number = {2},
           journaltitle = {The International Journal of Robotics Research},
           author = {Kaess, Michael and Johannsson, Hordur and Roberts, Richard and Ila, Viorela and Leonard, John J and Dellaert, Frank},
           urldate = {2017-07-11},
           date = {2012-02},
           langid = {english},
           file = {07-IJR430419.dvi - 0278364911430419:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/SCNFIKPV/0278364911430419.pdf:application/pdf}
          }

          @incollection{konolige_large-scale_2010,
           title = {Large-scale visual odometry for rough terrain},
           url = {https://link.springer.com/chapter/10.1007/978-3-642-14743-2_18},
           pages = {201--212},
           booktitle = {Robotics research},
           publisher = {Springer},
           author = {Konolige, Kurt and Agrawal, Motilal and Sola, Joan},
           urldate = {2017-07-11},
           date = {2010},
           file = {Title - 978-3-642-14743-2_18.pdf:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/6WGVC2FW/10.1007978-3-642-14743-2_18.pdf:application/pdf}
          }

          @article{scaramuzza_visual_2011,
           title = {Visual Odometry [Tutorial]},
           volume = {18},
           issn = {1070-9932},
           doi = {10.1109/MRA.2011.943233},
           abstract = {Visual odometry ({VO}) is the process of estimating the egomotion of an agent (e.g., vehicle, human, and robot) using only the input of a single or If multiple cameras attached to it. Application domains include robotics, wearable computing, augmented reality, and automotive. The term {VO} was coined in 2004 by Nister in his landmark paper. The term was chosen for its similarity to wheel odometry, which incrementally estimates the motion of a vehicle by integrating the number of turns of its wheels over time. Likewise, {VO} operates by incrementally estimating the pose of the vehicle through examination of the changes that motion induces on the images of its onboard cameras. For {VO} to work effectively, there should be sufficient illumination in the environment and a static scene with enough texture to allow apparent motion to be extracted. Furthermore, consecutive frames should be captured by ensuring that they have sufficient scene overlap.},
           pages = {80--92},
           number = {4},
           journaltitle = {{IEEE} Robotics Automation Magazine},
           author = {Scaramuzza, D. and Fraundorfer, F.},
           date = {2011-12},
           keywords = {Motion estimation, Robots, cameras, pose estimation, road vehicles, robotics, visual odometry, image texture, wheels, augmented reality, automotive, egomotion estimation, illumination, multiple cameras, onboard cameras, scene overlap, single camera, vehicle, wearable computing, wheel odometry},
           file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/IHC4ZAQW/6096039.html:text/html;IEEE Xplore Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/FFPRT57Z/Scaramuzza et Fraundorfer - 2011 - Visual Odometry [Tutorial].pdf:application/pdf}
          }

          @incollection{huang_visual_2017,
           title = {Visual Odometry and Mapping for Autonomous Flight Using an {RGB}-D Camera},
           isbn = {978-3-319-29362-2 978-3-319-29363-9},
           url = {https://link.springer.com/chapter/10.1007/978-3-319-29363-9_14},
           series = {Springer Tracts in Advanced Robotics},
           abstract = {{RGB}-D cameras provide both a color image and per-pixel depth estimates. The richness of their data and the recent development of low-cost sensors have combined to present an attractive opportunity for mobile robotics research. In this paper, we describe a system for visual odometry and mapping using an {RGB}-D camera, and its application to autonomous flight. By leveraging results from recent state-of-the-art algorithms and hardware, our system enables 3D flight in cluttered environments using only onboard sensor data. All computation and sensing required for local position control are performed onboard the vehicle, reducing the dependence on unreliable wireless links. We evaluate the effectiveness of our system for stabilizing and controlling a quadrotor micro air vehicle, demonstrate its use for constructing detailed 3D maps of an indoor environment, and discuss its limitations.},
           pages = {235--252},
           booktitle = {Robotics Research},
           publisher = {Springer, Cham},
           author = {Huang, Albert S. and Bachrach, Abraham and Henry, Peter and Krainin, Michael and Maturana, Daniel and Fox, Dieter and Roy, Nicholas},
           urldate = {2017-07-11},
           date = {2017},
           langid = {english},
           note = {{DOI}: 10.1007/978-3-319-29363-9\_14},
           file = {Huang-ISRR-2011.pdf:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/URMMWGQ7/Huang-ISRR-2011.pdf:application/pdf;Snapshot:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/RKAV6FP7/978-3-319-29363-9_14.html:text/html}
          }

          @inproceedings{nister_visual_2004,
           title = {Visual odometry},
           volume = {1},
           doi = {10.1109/CVPR.2004.1315094},
           abstract = {We present a system that estimates the motion of a stereo head or a single moving camera based on video input. The system operates in real-time with low delay and the motion estimates are used for navigational purposes. The front end of the system is a feature tracker. Point features are matched between pairs of frames and linked into image trajectories at video rate. Robust estimates of the camera motion are then produced from the feature tracks using a geometric hypothesize-and-test architecture. This generates what we call visual odometry, i.e. motion estimates from visual input alone. No prior knowledge of the scene nor the motion is necessary. The visual odometry can also be used in conjunction with information from other sources such as {GPS}, inertia sensors, wheel encoders, etc. The pose estimation method has been applied successfully to video from aerial, automotive and handheld platforms. We focus on results with an autonomous ground vehicle. We give examples of camera trajectories estimated purely from images over previously unseen distances and periods of time.},
           eventtitle = {Proceedings of the 2004 {IEEE} Computer Society Conference on Computer Vision and Pattern Recognition, 2004. {CVPR} 2004.},
           pages = {I--652--I--659 Vol.1},
           booktitle = {Proceedings of the 2004 {IEEE} Computer Society Conference on Computer Vision and Pattern Recognition, 2004. {CVPR} 2004.},
           author = {Nister, D. and Naroditsky, O. and Bergen, J.},
           date = {2004-06},
           keywords = {Delay estimation, Global Positioning System, Layout, Motion estimation, Navigation, Real time systems, Robustness, Vehicles, camera motion, cameras, image matching, tracking, video signal processing, visual odometry, inertial navigation, video cameras, aerial platforms, automotive platforms, autonomous ground vehicle, camera trajectories, feature tracker, geometric hypothesize-and-test architecture, handheld platforms, image trajectories, pose estimation method, robust estimation, single moving camera, stereo head, video rate, Head},
           file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/PZ9J6RUT/1315094.html:text/html;IEEE Xplore Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/EBZ46Q2A/Nister et al. - 2004 - Visual odometry.pdf:application/pdf}
          }

          @article{huang_computational_2008,
           title = {A computational interface for thermodynamic calculations software {MTDATA}},
           volume = {32},
           url = {http://www.sciencedirect.com/science/article/pii/S0364591607000648},
           pages = {129--134},
           number = {1},
           journaltitle = {Calphad},
           author = {Huang, Zhiheng and Conway, Paul P. and Thomson, Rachel C. and Dinsdale, Alan T. and Robinson, Jim {AJ}},
           urldate = {2017-07-20},
           date = {2008},
           file = {gtsam - gtsam.pdf:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/3Q4A7H2B/gtsam.pdf:application/pdf}
          }

          @inproceedings{prakhya_closed-form_2015,
           title = {A closed-form estimate of 3D {ICP} covariance},
           doi = {10.1109/MVA.2015.7153246},
           abstract = {We present a closed-form solution to estimate the covariance of the resultant transformation provided by the Iterative Closest Point ({ICP}) algorithm for 3D point cloud registration. We extend an existing work [1] that estimates {ICP}'s covariance in 2D with point to plane error metric to 3D with point to point and point to plane error metrics. Moreover, we do not make any assumption on the noise present in the sensor data and have no constraints on the estimated rigid transformation. The source code of our implementation is made publicly available, which can be adapted to work for {ICP} with different error metrics with minor changes. Our preliminary results show that {ICP}'s covariance is lower at a global minimum than at a local minima.},
           eventtitle = {2015 14th {IAPR} International Conference on Machine Vision Applications ({MVA})},
           pages = {526--529},
           booktitle = {2015 14th {IAPR} International Conference on Machine Vision Applications ({MVA})},
           author = {Prakhya, S. M. and Bingbing, L. and Rui, Y. and Lin, W.},
           date = {2015-05},
           keywords = {Estimation, Iterative closest point algorithm, Three-dimensional displays, image matching, image registration, image sensors, iterative methods, stereo image processing, covariance analysis, estimation theory, image coding, source coding, 3D {ICP} covariance, 3D point cloud registration, {ICP} algorithm, closed-form estimate, point-to-plane error metric, point-to-point error metrics, sensor data, source code, Data models, Jacobian matrices, Linear programming, Measurement},
           file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/3ZUS9VAM/7153246.html:text/html;IEEE Xplore Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/KG2JFIBQ/Prakhya et al. - 2015 - A closed-form estimate of 3D ICP covariance.pdf:application/pdf}
          }

          @inproceedings{censi_accurate_2007,
           title = {An accurate closed-form estimate of {ICP}'s covariance},
           doi = {10.1109/ROBOT.2007.363961},
           abstract = {Existing methods for estimating the covariance of the {ICP} (iterative closest/corresponding point) algorithm are either inaccurate or are computationally too expensive to be used online. This paper proposes a new method, based on the analysis of the error function being minimized. It considers that the correspondences are not independent (the same measurement being used in more than one correspondence), and explicitly utilizes the covariance matrix of the measurements, which are not assumed to be independent either. The validity of the approach is verified through extensive simulations: it is more accurate than previous methods and its computational load is negligible. The ill-posedness of the surface matching problem is explicitly tackled for under-constrained situations by performing an observability analysis; in the analyzed cases the method still provides a good estimate of the error projected on the observable manifold.},
           eventtitle = {Proceedings 2007 {IEEE} International Conference on Robotics and Automation},
           pages = {3167--3172},
           booktitle = {Proceedings 2007 {IEEE} International Conference on Robotics and Automation},
           author = {Censi, A.},
           date = {2007-04},
           keywords = {Iterative algorithms, Iterative closest point algorithm, Robot sensing systems, Robotics and automation, iterative methods, simultaneous localization and mapping, estimation theory, closed-form estimate, covariance matrices, {ICP} covariance estimation, covariance matrix, iterative corresponding point algorithm, observability analysis, surface matching, Error analysis, Impedance matching, Performance analysis, Random variables},
           file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/KSVJQ8D4/4209579.html:text/html;IEEE Xplore Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/XK7WWTNN/Censi - 2007 - An accurate closed-form estimate of ICP's covarian.pdf:application/pdf}
          }

          @inproceedings{azpiazu_vind:_2016,
           title = {Vind: a robot self-localization framework},
           isbn = {978-1-4503-5213-0},
           url = {http://dl.acm.org/citation.cfm?doid=3029610.3029612},
           doi = {10.1145/3029610.3029612},
           shorttitle = {Vind},
           pages = {1--6},
           publisher = {{ACM} Press},
           author = {Azpiazu, Jon and Bjerkeng, Magnus and Grøtli, Esten Ingar},
           urldate = {2017-07-27},
           date = {2016},
           langid = {english},
           file = {p1-Azpiazu.pdf:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/U3K7DR6Q/p1-Azpiazu.pdf:application/pdf}
          }

          @article{doaa_comparison_2013,
           title = {Comparison of optimization techniques for 3d graph-based slam},
           url = {https://www.researchgate.net/profile/Mohamed_Roushdy3/publication/259006970_Comparison_of_Optimization_Techniques_for_3D_Graph-based_SLAM/links/00b49529b847407fc5000000.pdf},
           journaltitle = {Recent Advances in Information Science},
           author = {Doaa, M. L. and Mohammed, A. and Salem, Megeed and Ramadan, H. and Roushdy, Mohamed I.},
           urldate = {2017-07-31},
           date = {2013},
           file = {- ECCS-31.pdf:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/E85R2KFG/ECCS-31.pdf:application/pdf}
          }

          @inproceedings{stoyanov_normal_2013,
           title = {Normal Distributions Transform Occupancy Map fusion: Simultaneous mapping and tracking in large scale dynamic environments},
           doi = {10.1109/IROS.2013.6697033},
           shorttitle = {Normal Distributions Transform Occupancy Map fusion},
           abstract = {Autonomous vehicles operating in real-world industrial environments have to overcome numerous challenges, chief among which are the creation of consistent 3D world models and the simultaneous tracking of the vehicle pose with respect to the created maps. In this paper we integrate two recently proposed algorithms in an online, near-realtime mapping and tracking system. Using the Normal Distributions Transform ({NDT}), a sparse Gaussian Mixture Model, for representation of 3D range scan data, we propose a frame-to-model registration and data fusion algorithm - {NDT} Fusion. The proposed approach uses a submap indexing system to achieve operation in arbitrarily-sized environments. The approach is evaluated on a publicly available city-block sized data set, achieving accuracy and runtime performance significantly better than current state of the art. In addition, the system is evaluated on a data set covering ten hours of operation and a trajectory of 7.2km in a real-world industrial environment, achieving centimeter accuracy at update rates of 5-10 Hz.},
           eventtitle = {2013 {IEEE}/{RSJ} International Conference on Intelligent Robots and Systems},
           pages = {4702--4708},
           booktitle = {2013 {IEEE}/{RSJ} International Conference on Intelligent Robots and Systems},
           author = {Stoyanov, T. and Saarinen, J. and Andreasson, H. and Lilienthal, A. J.},
           date = {2013-11},
           keywords = {Accuracy, Autonomous vehicles, Gaussian processes, {SLAM} (robots), Three-dimensional displays, Trajectory, Vehicles, image registration, mobile robots, object tracking, robot vision, simultaneous localization and mapping, vehicle pose, data structures, image fusion, indexing, industrial robots, solid modelling, 3D range scan data, 3D range scan data representation, 3D world models, {NDT}, arbitrarily-sized environments, city-block sized data set, data fusion algorithm, frame-to-model registration, frequency 5 Hz to 10 Hz, large scale dynamic environments, normal distribution transform occupancy map fusion, online near-real-time mapping and tracking system, real-world industrial environments, simultaneous mapping and tracking, sparse Gaussian mixture model, submap indexing system, time 10 hour, Gaussian distribution, Runtime},
           file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/DKT3NWS3/6697033.html:text/html;IEEE Xplore Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/EJNR3WWI/Stoyanov et al. - 2013 - Normal Distributions Transform Occupancy Map fusio.pdf:application/pdf}
          }

          @inproceedings{andreasson_fast_2015,
           title = {Fast, continuous state path smoothing to improve navigation accuracy},
           doi = {10.1109/ICRA.2015.7139250},
           abstract = {Autonomous navigation in real-world industrial environments is a challenging task in many respects. One of the key open challenges is fast planning and execution of trajectories to reach arbitrary target positions and orientations with high accuracy and precision, while taking into account non-holonomic vehicle constraints. In recent years, lattice-based motion planners have been successfully used to generate kinematically and kinodynamically feasible motions for non-holonomic vehicles. However, the discretized nature of these algorithms induces discontinuities in both state and control space of the obtained trajectories, resulting in a mismatch between the achieved and the target end pose of the vehicle. As endpose accuracy is critical for the successful loading and unloading of cargo in typical industrial applications, automatically planned paths have not be widely adopted in commercial {AGV} systems. The main contribution of this paper addresses this shortcoming by introducing a path smoothing approach, which builds on the output of a lattice-based motion planner to generate smooth drivable trajectories for non-holonomic industrial vehicles. In real world tests presented in this paper we demonstrate that the proposed approach is fast enough for online use (it computes trajectories faster than they can be driven) and highly accurate. In 100 repetitions we achieve mean end-point pose errors below 0.01 meters in translation and 0.002 radians in orientation. Even the maximum errors are very small: only 0.02 meters in translation and 0.008 radians in orientation.},
           eventtitle = {2015 {IEEE} International Conference on Robotics and Automation ({ICRA})},
           pages = {662--669},
           booktitle = {2015 {IEEE} International Conference on Robotics and Automation ({ICRA})},
           author = {Andreasson, H. and Saarinen, J. and Cirillo, M. and Stoyanov, T. and Lilienthal, A. J.},
           date = {2015-05},
           keywords = {Accuracy, Navigation, Trajectory, mobile robots, path planning, space vehicles, smoothing methods, industrial robots, automatic guided vehicles, {AGV} systems, automatically guided vehicles, autonomous navigation, car-like vehicles, continuous state path smoothing, lattice-based motion planner, mean end-point pose errors, nonholonomic industrial vehicles, Lattices},
           file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/94T6DZWK/7139250.html:text/html;IEEE Xplore Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/WGZZSBQB/Andreasson et al. - 2015 - Fast, continuous state path smoothing to improve n.pdf:application/pdf}
          }

          @inproceedings{saarinen_normal_2013,
           title = {Normal Distributions Transform Occupancy Maps: Application to large-scale online 3D mapping},
           doi = {10.1109/ICRA.2013.6630878},
           shorttitle = {Normal Distributions Transform Occupancy Maps},
           abstract = {Autonomous vehicles operating in real-world industrial environments have to overcome numerous challenges, chief among which is the creation and maintenance of consistent 3D world models. This paper proposes to address the challenges of online real-world mapping by building upon previous work on compact spatial representation and formulating a novel 3D mapping approach - the Normal Distributions Transform Occupancy Map ({NDT}-{OM}). The presented algorithm enables accurate real-time 3D mapping in large-scale dynamic environments employing a recursive update strategy. In addition, the proposed approach can seamlessly provide maps at multiple resolutions allowing for fast utilization in high-level functions such as localization or path planning. Compared to previous approaches that use the {NDT} representation, the proposed {NDT}-{OM} formulates an exact and efficient recursive update formulation and models the full occupancy of the map.},
           eventtitle = {2013 {IEEE} International Conference on Robotics and Automation},
           pages = {2233--2238},
           booktitle = {2013 {IEEE} International Conference on Robotics and Automation},
           author = {Saarinen, J. and Andreasson, H. and Stoyanov, T. and Ala-Luhtala, J. and Lilienthal, A. J.},
           date = {2013-05},
           keywords = {Accuracy, Real-time systems, Three-dimensional displays, autonomous vehicle, mobile robots, path planning, Transforms, Gaussian distribution, 3D world model, {NDT}-{OM}, compact spatial represenation, high-level function, large-scale dynamic environment, large-scale online 3D mapping, normal distributions transform occupancy map, online real-world mapping, real-time 3D mapping, recursive update formulation, recursive update strategy, Erbium, Sensors},
           file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/3AVBIE2C/6630878.html:text/html;IEEE Xplore Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/9KBFGQEW/Saarinen et al. - 2013 - Normal Distributions Transform Occupancy Maps App.pdf:application/pdf}
          }

          @article{magnusson_automatic_2009,
           title = {Automatic appearance-based loop detection from three-dimensional laser data using the normal distributions transform},
           volume = {26},
           issn = {1556-4967},
           url = {http://onlinelibrary.wiley.com/doi/10.1002/rob.20314/abstract},
           doi = {10.1002/rob.20314},
           abstract = {We propose a new approach to appearance-based loop detection for mobile robots, using three-dimensional (3D) laser scans. Loop detection is an important problem in the simultaneous localization and mapping ({SLAM}) domain, and, because it can be seen as the problem of recognizing previously visited places, it is an example of the data association problem. Without a flat-floor assumption, two-dimensional laser-based approaches are bound to fail in many cases. Two of the problems with 3D approaches that we address in this paper are how to handle the greatly increased amount of data and how to efficiently obtain invariance to 3D rotations. We present a compact representation of 3D point clouds that is still discriminative enough to detect loop closures without false positives (i.e., detecting loop closure where there is none). A low false-positive rate is very important because wrong data association could have disastrous consequences in a {SLAM} algorithm. Our approach uses only the appearance of 3D point clouds to detect loops and requires no pose information. We exploit the normal distributions transform surface representation to create feature histograms based on surface orientation and smoothness. The surface shape histograms compress the input data by two to three orders of magnitude. Because of the high compression rate, the histograms can be matched efficiently to compare the appearance of two scans. Rotation invariance is achieved by aligning scans with respect to dominant surface orientations. We also propose to use expectation maximization to fit a gamma mixture model to the output similarity measures in order to automatically determine the threshold that separates scans at loop closures from nonoverlapping ones. We discuss the problem of determining ground truth in the context of loop detection and the difficulties in comparing the results of the few available methods based on range information. Furthermore, we present quantitative performance evaluations using three real-world data sets, one of which is highly self-similar, showing that the proposed method achieves high recall rates (percentage of correctly identified loop closures) at low false-positive rates in environments with different characteristics. © 2009 Wiley Periodicals, Inc.},
           pages = {892--914},
           number = {11},
           journaltitle = {Journal of Field Robotics},
           shortjournal = {J. Field Robotics},
           author = {Magnusson, Martin and Andreasson, Henrik and Nüchter, Andreas and Lilienthal, Achim J.},
           urldate = {2017-09-22},
           date = {2009-11-01},
           langid = {english},
           file = {Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/K65B7SA9/Magnusson et al. - 2009 - Automatic appearance-based loop detection from thr.pdf:application/pdf;Snapshot:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/RSG5WAUN/abstract.html:text/html}
          }

          @article{stoyanov_fast_2012,
           title = {Fast and accurate scan registration through minimization of the distance between compact 3D {NDT} representations},
           volume = {31},
           issn = {0278-3649, 1741-3176},
           url = {http://journals.sagepub.com/doi/10.1177/0278364912460895},
           doi = {10.1177/0278364912460895},
           pages = {1377--1393},
           number = {12},
           journaltitle = {The International Journal of Robotics Research},
           author = {Stoyanov, Todor and Magnusson, Martin and Andreasson, Henrik and Lilienthal, Achim J},
           urldate = {2017-09-22},
           date = {2012-10},
           langid = {english},
           file = {3_IJR460895.dvi - 0278364912460895:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/GUWFRQPA/0278364912460895.pdf:application/pdf}
          }

          @article{riegler_octnet:_2016,
           title = {{OctNet}: Learning Deep 3D Representations at High Resolutions},
           url = {http://arxiv.org/abs/1611.05009},
           shorttitle = {{OctNet}},
           abstract = {We present {OctNet}, a representation for deep learning with sparse 3D data. In contrast to existing models, our representation enables 3D convolutional networks which are both deep and high resolution. Towards this goal, we exploit the sparsity in the input data to hierarchically partition the space using a set of unbalanced octrees where each leaf node stores a pooled feature representation. This allows to focus memory allocation and computation to the relevant dense regions and enables deeper networks without compromising resolution. We demonstrate the utility of our {OctNet} representation by analyzing the impact of resolution on several 3D tasks including 3D object classification, orientation estimation and point cloud labeling.},
           journaltitle = {{arXiv}:1611.05009 [cs]},
           author = {Riegler, Gernot and Ulusoy, Ali Osman and Geiger, Andreas},
           urldate = {2017-10-17},
           date = {2016-11-15},
           eprinttype = {arxiv},
           eprint = {1611.05009},
           keywords = {Computer Science - Computer Vision and Pattern Recognition},
           file = {arXiv\:1611.05009 PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/RETSXFQD/Riegler et al. - 2016 - OctNet Learning Deep 3D Representations at High R.pdf:application/pdf;arXiv.org Snapshot:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/45RBAP62/1611.html:text/html}
          }

          @collection{kaneko_robotics_2011,
           location = {Berlin, Heidelberg},
           title = {Robotics Research},
           volume = {66},
           isbn = {978-3-642-14742-5 978-3-642-14743-2},
           url = {http://link.springer.com/10.1007/978-3-642-14743-2},
           series = {Springer Tracts in Advanced Robotics},
           publisher = {Springer Berlin Heidelberg},
           editor = {Kaneko, Makoto and Nakamura, Yoshihiko},
           editorb = {Siciliano, Bruno and Khatib, Oussama and Groen, Frans},
           editorbtype = {redactor},
           urldate = {2017-11-09},
           date = {2011},
           note = {{DOI}: 10.1007/978-3-642-14743-2},
           file = {Title - 978-3-642-14743-2.pdf:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/UR92PRC7/10.1007978-3-642-14743-2.pdf:application/pdf}
          }

          @inproceedings{guizilini_visual_2011,
           title = {Visual odometry learning for unmanned aerial vehicles},
           doi = {10.1109/ICRA.2011.5979706},
           abstract = {This paper addresses the problem of using visual information to estimate vehicle motion (a.k.a. visual odometry) from a machine learning perspective. The vast majority of current visual odometry algorithms are heavily based on geometry, using a calibrated camera model to recover relative translation (up to scale) and rotation by tracking image features over time. Our method eliminates the need for a parametric model by jointly learning how image structure and vehicle dynamics affect camera motion. This is achieved with a Gaussian Process extension, called Coupled {GP}, which is trained in a supervised manner to infer the underlying function mapping optical flow to relative translation and rotation. Matched image features parameters are used as inputs and linear and angular velocities are the outputs in our non-linear multi-task regression problem. We show here that it is possible, using a single uncalibrated camera and establishing a first-order temporal dependency between frames, to jointly estimate not only a full 6 {DoF} motion (along with a full covariance matrix) but also relative scale, a non-trivial problem in monocular configurations. Experiments were performed with imagery collected with an unmanned aerial vehicle ({UAV}) flying over a deserted area at speeds of 100-120 km/h and altitudes of 80-100 m, a scenario that constitutes a challenge for traditional visual odometry estimators.},
           eventtitle = {2011 {IEEE} International Conference on Robotics and Automation},
           pages = {6213--6220},
           booktitle = {2011 {IEEE} International Conference on Robotics and Automation},
           author = {Guizilini, V. and Ramos, F.},
           date = {2011-05},
           keywords = {Remotely operated vehicles, Unmanned aerial vehicles, Vehicles, Visualization, camera motion, cameras, distance measurement, image sequences, regression analysis, covariance matrix, aircraft, learning (artificial intelligence), Gaussian process, calibrated camera model, coupled {GP}, function mapping optical flow, geometry, image features tracking, image structure, machine learning, nonlinear multitask regression problem, vehicle dynamics, vehicle motion, visual information, visual odometry learning, Optical sensors, Training},
           file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/7KIV2TWV/5979706.html:text/html;IEEE Xplore Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/69Z75ZFS/Guizilini et Ramos - 2011 - Visual odometry learning for unmanned aerial vehic.pdf:application/pdf}
          }

          @article{mur-artal_orb-slam2:_2017,
           title = {{ORB}-{SLAM}2: an Open-Source {SLAM} System for Monocular, Stereo and {RGB}-D Cameras},
           volume = {33},
           issn = {1552-3098, 1941-0468},
           url = {http://arxiv.org/abs/1610.06475},
           doi = {10.1109/TRO.2017.2705103},
           shorttitle = {{ORB}-{SLAM}2},
           abstract = {We present {ORB}-{SLAM}2 a complete {SLAM} system for monocular, stereo and {RGB}-D cameras, including map reuse, loop closing and relocalization capabilities. The system works in real-time on standard {CPUs} in a wide variety of environments from small hand-held indoors sequences, to drones flying in industrial environments and cars driving around a city. Our back-end based on bundle adjustment with monocular and stereo observations allows for accurate trajectory estimation with metric scale. Our system includes a lightweight localization mode that leverages visual odometry tracks for unmapped regions and matches to map points that allow for zero-drift localization. The evaluation on 29 popular public sequences shows that our method achieves state-of-the-art accuracy, being in most cases the most accurate {SLAM} solution. We publish the source code, not only for the benefit of the {SLAM} community, but with the aim of being an out-of-the-box {SLAM} solution for researchers in other fields.},
           pages = {1255--1262},
           number = {5},
           journaltitle = {{IEEE} Transactions on Robotics},
           author = {Mur-Artal, Raul and Tardos, Juan D.},
           urldate = {2017-11-09},
           date = {2017-10},
           eprinttype = {arxiv},
           eprint = {1610.06475},
           keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Robotics},
           file = {arXiv\:1610.06475 PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/58R6ZXBW/Mur-Artal et Tardos - 2017 - ORB-SLAM2 an Open-Source SLAM System for Monocula.pdf:application/pdf;arXiv.org Snapshot:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/6NA5QFIR/1610.html:text/html}
          }

          @online{_kitti_????,
           title = {The {KITTI} Vision Benchmark Suite},
           url = {http://www.cvlibs.net/datasets/kitti/eval_odometry.php},
           urldate = {2017-11-09},
           file = {The KITTI Vision Benchmark Suite:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/5GNDNDXF/eval_odometry.html:text/html}
          }

          @inproceedings{rouxel_learning_2016,
           title = {Learning the odometry on a small humanoid robot},
           doi = {10.1109/ICRA.2016.7487326},
           abstract = {Odometry is an important element for the localization of mobile robots. For humanoid robots, it is very prone to integration errors, due to mechanical complexity, uncertainties and foot/ground contacts. Most of the time, a visual odometry is then used to encompass these problems. In this work we propose a method to compensate for odometry drifting using machine learning on a small size low-cost humanoid without vision. This method is tested on different ground conditions and exhibits a significant improvement in odometry accuracy.},
           eventtitle = {2016 {IEEE} International Conference on Robotics and Automation ({ICRA})},
           pages = {1810--1816},
           booktitle = {2016 {IEEE} International Conference on Robotics and Automation ({ICRA})},
           author = {Rouxel, Q. and Passault, G. and Hofer, L. and N'Guyen, S. and Ly, O.},
           date = {2016-05},
           keywords = {Foot, gait analysis, Kinematics, legged locomotion, Computational modeling, Robot sensing systems, distance measurement, humanoid robots, robot vision, visual odometry, learning (artificial intelligence), machine learning, compensation, foot-ground contacts, ground conditions, integration errors, Legged locomotion, mechanical complexity, mobile robot localization, odometry accuracy improvement, odometry drifting compensation, odometry learning, small-size low-cost humanoid robot, system uncertainties},
           file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/K85JY4HD/7487326.html:text/html}
          }

          @inproceedings{roberts_memory-based_2008,
           title = {Memory-based learning for visual odometry},
           doi = {10.1109/ROBOT.2008.4543185},
           abstract = {We present and examine a technique for estimating the ego-motion of a mobile robot using memory-based learning and a monocular camera. Unlike other approaches that rely heavily on camera calibration and geometry to compute trajectory, our method learns a mapping from sparse optical flow to platform velocity and turn rate. We also demonstrate an efficient method of computing high-quality sparse optical flow, and techniques for using this sparse optical flow as input to a supervised learning method. We employ a voting scheme of many learners that use subsets of the sparse optical flow to cope with variable dimensionality and reduce the dimensionality of each learner. Finally, we perform experiments in which we examine the learned mapping for visual odometry, investigate the effects of varying the reduced dimensionality of the sparse optical flow state, and quantify the accuracy of two variations of our learner scheme. Our results indicate that our learning scheme estimates monocular visual odometry mainly from points on the ground plane, and reflect to a degree the minimum dimensionality imposed by the problem. In addition, we show that while this memory-based learning method cannot yet estimate ego-motion as accurately as recent geometric methods, it is possible to learn, with no explicit model of camera calibration or scene structure, complicated mappings that take advantage of properties of the camera and the environment.},
           eventtitle = {2008 {IEEE} International Conference on Robotics and Automation},
           pages = {47--52},
           booktitle = {2008 {IEEE} International Conference on Robotics and Automation},
           author = {Roberts, R. and Nguyen, Hai and Krishnamurthi, N. and Balch, T.},
           date = {2008-05},
           keywords = {Robot vision systems, Trajectory, distance measurement, ego-motion estimation, image sequences, mobile robots, robot vision, visual odometry, Geometrical optics, video cameras, learning (artificial intelligence), Calibration, Cameras, Computational geometry, geometric method, Image motion analysis, memory-based learning method, Mobile robots, monocular camera calibration, motion estimation, Optical computing, sparse optical flow, Supervised learning, supervised learning method, voting scheme},
           file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/CVDEZ5Q9/4543185.html:text/html}
          }

          @inproceedings{konda_learning_2015,
           title = {Learning Visual Odometry with a Convolutional Network.},
           pages = {486--490},
           booktitle = {{VISAPP} (1)},
           author = {Konda, Kishore Reddy and Memisevic, Roland},
           date = {2015},
           file = {28c163458f5a2ba7202cec0e6128665dc30a.pdf:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/L2XLDLBD/28c163458f5a2ba7202cec0e6128665dc30a.pdf:application/pdf}
          }

          @article{gonzalez_slippage_????,
           title = {Slippage and immobilization detection for planetary exploration rovers via machine learning and proprioceptive sensing},
           issn = {1556-4967},
           url = {http://onlinelibrary.wiley.com/doi/10.1002/rob.21736/abstract},
           doi = {10.1002/rob.21736},
           abstract = {This paper presents a new methodology where machine learning is used for detecting various levels of slip in the context of planetary exploration robotic missions. This methodology aims at employing proprioceptive rover sensor signals. Consequently, no operational complexity is added to the rover's commanding and it is independent of lighting conditions. Two supervised learning methods (Support Vector Machines and Artificial Neural Networks) are compared to two unsupervised learning approaches (K-means and Self-Organizing Maps ({SOM})). Physical experiments using a single-wheel testbed equipped with an {MSL} spare wheel and a real planetary exploration rover validate the implemented methodology. Performance is evaluated in terms of well-known metrics both considering single data points and subsets of consecutive data points (moving median filter). Computation time and storage requirements are also examined. One of the {SOM}-based algorithms, semantic {SOM} method, demonstrates a proper balance between the benefits of supervised learning algorithms (high success rate, {\textgreater}96\%) and the advantages of unsupervised learning methods (low storage requirements, 5 kb, and no need of manually-labeled training data). This paper also addresses the most convenient placement of {IMU} sensors on the rover chassis such that slippage detection is maximized.},
           pages = {n/a--n/a},
           journaltitle = {Journal of Field Robotics},
           shortjournal = {J. Field Robotics},
           author = {Gonzalez, Ramon and Apostolopoulos, Dimi and Iagnemma, Karl},
           urldate = {2017-12-04},
           langid = {english},
           keywords = {{IMU} placement, {LATUV} rover, mars science laboratory ({MSL}) rover, {MIT} single-wheel testbed, self-organizing map ({SOM}), slip},
           file = {Full Text PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/W9VG7IQT/Gonzalez et al. - Slippage and immobilization detection for planetar.pdf:application/pdf;Snapshot:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/GTQLMW5N/abstract.html:text/html}
          }

          @article{lu_learning_2017,
           title = {Learning Image Relations with Contrast Association Networks},
           url = {http://arxiv.org/abs/1705.05665},
           abstract = {Inferring the relations between two images is an important class of tasks in computer vision. Examples of such tasks include computing optical flow and stereo disparity. We treat the relation inference tasks as a machine learning problem and tackle it with neural networks. A key to the problem is learning a representation of relations. We propose a new neural network module, contrast association unit ({CAU}), which explicitly models the relations between two sets of input variables. Due to the non-negativity of the weights in {CAU}, we adopt a multiplicative update algorithm for learning these weights. Experiments show that neural networks with {CAUs} are more effective in learning five fundamental image transformations than conventional neural networks.},
           journaltitle = {{arXiv}:1705.05665 [cs]},
           author = {Lu, Yao and Yang, Zhirong and Kannala, Juho and Kaski, Samuel},
           urldate = {2017-12-04},
           date = {2017-05-16},
           eprinttype = {arxiv},
           eprint = {1705.05665},
           keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Learning},
           file = {arXiv\:1705.05665 PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/94VYERT3/Lu et al. - 2017 - Learning Image Relations with Contrast Association.pdf:application/pdf;arXiv.org Snapshot:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/GHVFT36M/1705.html:text/html;s11.pdf:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/QDAKK6MQ/s11.pdf:application/pdf;Zhang.pdf:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/M56MRSJL/Zhang.pdf:application/pdf}
          }

          @book{apt_principles_2003,
           location = {Cambridge ; New York},
           title = {Principles of constraint programming},
           isbn = {978-0-521-82583-2},
           pagetotal = {407},
           publisher = {Cambridge University Press},
           author = {Apt, Krzysztof R.},
           date = {2003},
           note = {{OCLC}: ocm52358589},
           keywords = {Constraint programming (Computer science)},
           file = {AnIntroductiontoMachineLearning - thebook.pdf:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/FKG9P8CU/thebook.pdf:application/pdf}
          }

          @article{bag_motion_2017,
           title = {Motion Estimation Using Visual Odometry and Deep Learning Localization},
           volume = {2017},
           issn = {2470-1173},
           url = {http://www.ingentaconnect.com/content/10.2352/ISSN.2470-1173.2017.19.AVM-022},
           doi = {10.2352/ISSN.2470-1173.2017.19.AVM-022},
           pages = {62--69},
           number = {19},
           journaltitle = {Electronic Imaging},
           author = {Bag, Suvam and Venkatachalapathy, Vishwas and Ptucha, {RaymondW}.},
           urldate = {2017-12-04},
           date = {2017-01-29},
           langid = {english},
           file = {s11.pdf:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/VQQW7SJZ/s11.pdf:application/pdf}
          }

          @thesis{zhang_research_2017,
           title = {Research on Trajectory Visualization of Ego-Motion Videos with Pedestrian Based on Monocular Visual Odometry and Machine Learning},
           institution = {Waseda University},
           type = {phdthesis},
           author = {Zhang, Yifei},
           date = {2017},
           file = {Zhang.pdf:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/TX7XL558/Zhang.pdf:application/pdf}
          }

          @article{blanco_subjective_2009,
           title = {Subjective local maps for hybrid metric-topological {SLAM}},
           volume = {57},
           issn = {09218890},
           url = {http://linkinghub.elsevier.com/retrieve/pii/S092188900800016X},
           doi = {10.1016/j.robot.2008.02.002},
           pages = {64--74},
           number = {1},
           journaltitle = {Robotics and Autonomous Systems},
           author = {Blanco, J.L. and González, J. and Fernández-Madrigal, J.-A.},
           urldate = {2017-12-04},
           date = {2009-01},
           langid = {english},
           file = {Subjective local maps for hybrid metric-topological SLAM - 1-s2.0-S092188900800016X-main.pdf:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/3TDQMTGR/1-s2.0-S092188900800016X-main.pdf:application/pdf}
          }

          @article{oliveira_topometric_2017,
           title = {Topometric Localization with Deep Learning},
           url = {http://arxiv.org/abs/1706.08775},
           abstract = {Compared to {LiDAR}-based localization methods, which provide high accuracy but rely on expensive sensors, visual localization approaches only require a camera and thus are more cost-effective while their accuracy and reliability typically is inferior to {LiDAR}-based methods. In this work, we propose a vision-based localization approach that learns from {LiDAR}-based localization methods by using their output as training data, thus combining a cheap, passive sensor with an accuracy that is on-par with {LiDAR}-based localization. The approach consists of two deep networks trained on visual odometry and topological localization, respectively, and a successive optimization to combine the predictions of these two networks. We evaluate the approach on a new challenging pedestrian-based dataset captured over the course of six months in varying weather conditions with a high degree of noise. The experiments demonstrate that the localization errors are up to 10 times smaller than with traditional vision-based localization methods.},
           journaltitle = {{arXiv}:1706.08775 [cs]},
           author = {Oliveira, Gabriel L. and Radwan, Noha and Burgard, Wolfram and Brox, Thomas},
           urldate = {2017-12-04},
           date = {2017-06-27},
           eprinttype = {arxiv},
           eprint = {1706.08775},
           keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Robotics},
           file = {arXiv\:1706.08775 PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/EB55QSRU/Oliveira et al. - 2017 - Topometric Localization with Deep Learning.pdf:application/pdf;arXiv.org Snapshot:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/N35CCK34/1706.html:text/html}
          }

          @article{turan_deep_2017,
           title = {Deep {EndoVO}: A recurrent convolutional neural network ({RCNN}) based visual odometry approach for endoscopic capsule robots},
           issn = {09252312},
           url = {http://linkinghub.elsevier.com/retrieve/pii/S092523121731665X},
           doi = {10.1016/j.neucom.2017.10.014},
           shorttitle = {Deep {EndoVO}},
           journaltitle = {Neurocomputing},
           author = {Turan, Mehmet and Almalioglu, Yasin and Araujo, Helder and Konukoglu, Ender and Sitti, Metin},
           urldate = {2017-12-04},
           date = {2017-11},
           langid = {english},
           file = {1-s2.0-S092523121731665X-main.pdf:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/UMQE9CHI/1-s2.0-S092523121731665X-main.pdf:application/pdf}
          }

          @inproceedings{muller_flowdometry:_2017,
           title = {Flowdometry: An Optical Flow and Deep Learning Based Approach to Visual Odometry},
           doi = {10.1109/WACV.2017.75},
           shorttitle = {Flowdometry},
           abstract = {Visual odometry is a challenging task related to simultaneous localization and mapping that aims to generate a map traveled from a visual data stream. Based on one or two cameras, motion is estimated from features and pixel differences between frames. Because of the frame rate of the cameras, there are generally small, incremental changes between subsequent frames where optical flow can be assumed to be proportional to the physical distance moved by an egocentric reference, such as a camera on a vehicle. In this paper, a visual odometry system called Flowdometry is proposed based on optical flow and deep learning. Optical flow images are used as input to a convolutional neural network, which calculates a rotation and displacement for each image pixel. The displacements and rotations are applied incrementally to construct a map of where the camera has traveled. The proposed system is trained and tested on the {KITTI} visual odometry dataset, and accuracy is measured by the difference in distances between ground truth and predicted driving trajectories. Different convolutional neural network architecture configurations are tested for accuracy, and then results are compared to other state-of-the-art monocular odometry systems using the same dataset. The average translation error from the Flowdometry system is 10.77\% and the average rotation error is 0.0623 degrees per meter. The total execution time of the system per optical flow frame is 0.633 seconds, which offers a 23.796x speedup over state-of-the-art methods using deep learning.},
           eventtitle = {2017 {IEEE} Winter Conference on Applications of Computer Vision ({WACV})},
           pages = {624--631},
           booktitle = {2017 {IEEE} Winter Conference on Applications of Computer Vision ({WACV})},
           author = {Muller, P. and Savakis, A.},
           date = {2017-03},
           keywords = {Computer architecture, Visualization, distance measurement, image sequences, Cameras, Adaptive optics, convolutional neural network architecture, deep learning, feedforward neural nets, Flowdometry, image pixel, monocular odometry systems, optical flow, Optical imaging, Optical network units, Video sequences, visual odometry system},
           file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/T5F9TQP4/7926658.html:text/html}
          }

          @article{liu_learning_2017,
           title = {Learning End-to-end Multimodal Sensor Policies for Autonomous Navigation},
           url = {http://arxiv.org/abs/1705.10422},
           abstract = {Multisensory polices are known to enhance both state estimation and target tracking. However, in the space of end-to-end sensorimotor control, this multi-sensor outlook has received limited attention. Moreover, systematic ways to make policies robust to partial sensor failure are not well explored. In this work, we propose a specific customization of Dropout, called {\textbackslash}textit\{Sensor Dropout\}, to improve multisensory policy robustness and handle partial failure in the sensor-set. We also introduce an additional auxiliary loss on the policy network in order to reduce variance in the band of potential multi- and uni-sensory policies to reduce jerks during policy switching triggered by an abrupt sensor failure or deactivation/activation. Finally, through the visualization of gradients, we show that the learned policies are conditioned on the same latent states representation despite having diverse observations spaces - a hallmark of true sensor-fusion. Simulation results of the multisensory policy, as visualized in {TORCS} racing game, can be seen here: https://youtu.be/{QAK}2lcXjNZc.},
           journaltitle = {{arXiv}:1705.10422 [cs]},
           author = {Liu, Guan-Horng and Siravuru, Avinash and Prabhakar, Sai and Veloso, Manuela and Kantor, George},
           urldate = {2017-12-04},
           date = {2017-05-29},
           eprinttype = {arxiv},
           eprint = {1705.10422},
           keywords = {Computer Science - Robotics, Computer Science - Learning, Computer Science - Artificial Intelligence},
           file = {arXiv\:1705.10422 PDF:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/QK4ZR9PB/Liu et al. - 2017 - Learning End-to-end Multimodal Sensor Policies for.pdf:application/pdf;arXiv.org Snapshot:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/ANJKPRFD/1705.html:text/html}
          }

          @online{_deep_????,
           title = {Deep Learning},
           url = {http://www.deeplearningbook.org/},
           urldate = {2017-12-05},
           file = {Deep Learning:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/WMFD9P52/www.deeplearningbook.org.html:text/html}
          }

          @article{westoby_structure--motion_2012,
           title = {‘Structure-from-Motion’ photogrammetry: A low-cost, effective tool for geoscience applications},
           volume = {179},
           issn = {0169555X},
           url = {http://linkinghub.elsevier.com/retrieve/pii/S0169555X12004217},
           doi = {10.1016/j.geomorph.2012.08.021},
           shorttitle = {‘Structure-from-Motion’ photogrammetry},
           pages = {300--314},
           journaltitle = {Geomorphology},
           author = {Westoby, M.J. and Brasington, J. and Glasser, N.F. and Hambrey, M.J. and Reynolds, J.M.},
           urldate = {2018-01-29},
           date = {2012-12},
           langid = {english},
           file = {1-s2.0-S0169555X12004217-main.pdf:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/UBAPICKW/1-s2.0-S0169555X12004217-main.pdf:application/pdf}
          }

          @article{arulampalam_tutorial_2002,
           title = {A tutorial on particle filters for online nonlinear/non-Gaussian Bayesian tracking},
           volume = {50},
           issn = {1053-587X},
           doi = {10.1109/78.978374},
           abstract = {Increasingly, for many application areas, it is becoming important to include elements of nonlinearity and non-Gaussianity in order to model accurately the underlying dynamics of a physical system. Moreover, it is typically crucial to process data on-line as it arrives, both from the point of view of storage costs as well as for rapid adaptation to changing signal characteristics. In this paper, we review both optimal and suboptimal Bayesian algorithms for nonlinear/non-Gaussian tracking problems, with a focus on particle filters. Particle filters are sequential Monte Carlo methods based on point mass (or "particle") representations of probability densities, which can be applied to any state-space model and which generalize the traditional Kalman filtering methods. Several variants of the particle filter such as {SIR}, {ASIR}, and {RPF} are introduced within a generic framework of the sequential importance sampling ({SIS}) algorithm. These are discussed and compared with the standard {EKF} through an illustrative example},
           pages = {174--188},
           number = {2},
           journaltitle = {{IEEE} Transactions on Signal Processing},
           author = {Arulampalam, M. S. and Maskell, S. and Gordon, N. and Clapp, T.},
           date = {2002-02},
           keywords = {Bayes methods, Bayesian methods, Filtering, Kalman filtering, Kalman filters, Monte Carlo methods, Particle filters, state estimation, Costs, filtering theory, importance sampling, {nonGaussian} tracking problems, Nonlinear dynamical systems, nonlinear tracking problems, optimal Bayesian algorithms, particle filters, Particle tracking, point mass representations, probability densities, sequential importance sampling, sequential Monte Carlo methods, Signal processing, state-space methods, state-space model, suboptimal Bayesian algorithms, tracking filters, tutorial, Tutorial},
           file = {IEEE Xplore Abstract Record:/home/virgile/.mozilla/firefox/u9rj1ge0.default/zotero/storage/W2YXLLFG/978374.html:text/html}
          }
